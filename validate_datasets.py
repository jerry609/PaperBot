"""
æ•°æ®é›†æ ¡éªŒè„šæœ¬
- æ£€æŸ¥ datasets/processed ä¸‹çš„ CSV æ˜¯å¦åŒ…å« text/label å­—æ®µ
- æ£€æŸ¥ metadata æ˜¯å¦åŒ…å« license/source
è¿è¡Œï¼špython scripts/validate_datasets.py
"""

import csv
import sys
from pathlib import Path
import yaml

ROOT = Path(__file__).parent.parent
PROCESSED_DIR = ROOT / "datasets" / "processed"
METADATA_DIR = ROOT / "datasets" / "metadata"


def validate_csv(path: Path):
    with path.open("r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        headers = reader.fieldnames or []
    missing = [c for c in ("text", "label") if c not in headers]
    return missing


def validate_metadata(name: str):
    meta_path = METADATA_DIR / f"{name}.yaml"
    if not meta_path.exists():
        return ["metadata_missing"]
    data = yaml.safe_load(meta_path.read_text(encoding="utf-8")) or {}
    missing = []
    if not data.get("license"):
        missing.append("license")
    if not data.get("source"):
        missing.append("source")
    return missing


def main():
    if not PROCESSED_DIR.exists():
        print("âš ï¸  datasets/processed ä¸å­˜åœ¨")
        sys.exit(1)

    any_error = False
    for csv_file in PROCESSED_DIR.glob("*.csv"):
        name = csv_file.stem
        missing_cols = validate_csv(csv_file)
        meta_missing = validate_metadata(name)

        if missing_cols:
            any_error = True
            print(f"âŒ {csv_file.name}: ç¼ºå°‘åˆ— {missing_cols}")
        else:
            print(f"âœ… {csv_file.name}: å­—æ®µé½å…¨")

        if meta_missing:
            any_error = True
            print(f"âš ï¸ {name}.yaml: ç¼ºå°‘ {meta_missing}")
        else:
            print(f"âœ… {name}.yaml: metadata å®Œæ•´")

    if any_error:
        sys.exit(1)
    print("ğŸ‰ æ•°æ®é›†æ ¡éªŒé€šè¿‡")


if __name__ == "__main__":
    main()

