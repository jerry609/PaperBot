# scholar_tracking/scheduler.py
"""
å®šæ—¶æ”¶å½•è°ƒåº¦å™¨ - å€Ÿé‰´ JobLeap çš„ä¿¡æ¯æ”¶å½•æœºåˆ¶
å®ç°å®šæœŸæ”¶å½•æ–°è®ºæ–‡ï¼Œæ ‡æ³¨æ”¶å½•æ—¶é—´ï¼Œæ”¯æŒç”¨æˆ·é€šçŸ¥
"""

import asyncio
import time
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any, Callable, Awaitable, Set
from datetime import datetime, timedelta
from enum import Enum
import json
import hashlib
from pathlib import Path

from .models import Scholar, PaperMeta
from .feed import FeedGenerator, FeedEventFactory, ScholarFeedService


class CollectionInterval(Enum):
    """æ”¶å½•é—´éš”"""
    HOURLY = 3600           # æ¯å°æ—¶
    DAILY = 86400           # æ¯å¤©
    WEEKLY = 604800         # æ¯å‘¨
    CUSTOM = 0              # è‡ªå®šä¹‰


class NotificationType(Enum):
    """é€šçŸ¥ç±»å‹"""
    NEW_PAPER = "new_paper"
    CITATION_MILESTONE = "citation_milestone"
    CONFERENCE_DEADLINE = "conference_deadline"
    WEEKLY_DIGEST = "weekly_digest"


@dataclass
class CollectionRecord:
    """æ”¶å½•è®°å½• - ç±»ä¼¼ JobLeap çš„ "æ”¶å½•æ—¶é—´" æ¦‚å¿µ"""
    
    paper_id: str
    scholar_id: str
    collected_at: datetime
    source: str = "semantic_scholar"
    
    # æ”¶å½•æ—¶çš„å¿«ç…§
    citation_count_at_collection: int = 0
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "paper_id": self.paper_id,
            "scholar_id": self.scholar_id,
            "collected_at": self.collected_at.isoformat(),
            "source": self.source,
            "citation_count_at_collection": self.citation_count_at_collection,
            "metadata": self.metadata,
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "CollectionRecord":
        return cls(
            paper_id=data["paper_id"],
            scholar_id=data["scholar_id"],
            collected_at=datetime.fromisoformat(data["collected_at"]),
            source=data.get("source", "semantic_scholar"),
            citation_count_at_collection=data.get("citation_count_at_collection", 0),
            metadata=data.get("metadata", {}),
        )


@dataclass
class NotificationConfig:
    """é€šçŸ¥é…ç½®"""
    
    enabled: bool = True
    
    # é€šçŸ¥ç±»å‹å¼€å…³
    notify_new_papers: bool = True
    notify_citation_milestones: bool = True
    notify_conference_deadlines: bool = True
    notify_weekly_digest: bool = True
    
    # å¼•ç”¨é‡Œç¨‹ç¢‘é˜ˆå€¼
    citation_milestones: List[int] = field(
        default_factory=lambda: [10, 50, 100, 500, 1000]
    )
    
    # é€šçŸ¥æ¸ é“
    channels: List[str] = field(default_factory=lambda: ["console"])
    
    # é™é»˜æ—¶é—´æ®µï¼ˆä¸å‘é€é€šçŸ¥ï¼‰
    quiet_hours: Optional[tuple] = None  # (start_hour, end_hour)


@dataclass
class SchedulerConfig:
    """è°ƒåº¦å™¨é…ç½®"""
    
    # æ”¶å½•é—´éš”
    collection_interval: CollectionInterval = CollectionInterval.DAILY
    custom_interval_seconds: int = 86400
    
    # æ”¶å½•è®¾ç½®
    max_papers_per_scholar: int = 100  # æ¯ä¸ªå­¦è€…æœ€å¤šæ”¶å½•è®ºæ–‡æ•°
    collect_recent_days: int = 30       # æ”¶å½•æœ€è¿‘Nå¤©çš„è®ºæ–‡
    
    # å­˜å‚¨è·¯å¾„
    data_dir: str = "./data/scheduler"
    
    # é€šçŸ¥é…ç½®
    notification: NotificationConfig = field(default_factory=NotificationConfig)
    
    # é‡è¯•é…ç½®
    max_retries: int = 3
    retry_delay_seconds: int = 60


class NotificationHandler:
    """é€šçŸ¥å¤„ç†å™¨"""
    
    def __init__(self, config: NotificationConfig):
        self.config = config
        self._handlers: Dict[str, Callable] = {
            "console": self._console_notify,
        }
    
    def register_handler(self, channel: str, handler: Callable):
        """æ³¨å†Œé€šçŸ¥å¤„ç†å™¨"""
        self._handlers[channel] = handler
    
    async def notify(
        self,
        notification_type: NotificationType,
        title: str,
        message: str,
        data: Optional[Dict[str, Any]] = None,
    ):
        """å‘é€é€šçŸ¥"""
        if not self.config.enabled:
            return
        
        # æ£€æŸ¥é™é»˜æ—¶é—´
        if self._is_quiet_hours():
            return
        
        # æ£€æŸ¥é€šçŸ¥ç±»å‹æ˜¯å¦å¯ç”¨
        if not self._is_notification_enabled(notification_type):
            return
        
        # å‘æ‰€æœ‰é…ç½®çš„æ¸ é“å‘é€é€šçŸ¥
        for channel in self.config.channels:
            handler = self._handlers.get(channel)
            if handler:
                try:
                    await handler(notification_type, title, message, data)
                except Exception as e:
                    print(f"Notification error on {channel}: {e}")
    
    def _is_quiet_hours(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨é™é»˜æ—¶é—´æ®µ"""
        if not self.config.quiet_hours:
            return False
        
        start, end = self.config.quiet_hours
        current_hour = datetime.now().hour
        
        if start <= end:
            return start <= current_hour < end
        else:
            return current_hour >= start or current_hour < end
    
    def _is_notification_enabled(self, notification_type: NotificationType) -> bool:
        """æ£€æŸ¥é€šçŸ¥ç±»å‹æ˜¯å¦å¯ç”¨"""
        type_map = {
            NotificationType.NEW_PAPER: self.config.notify_new_papers,
            NotificationType.CITATION_MILESTONE: self.config.notify_citation_milestones,
            NotificationType.CONFERENCE_DEADLINE: self.config.notify_conference_deadlines,
            NotificationType.WEEKLY_DIGEST: self.config.notify_weekly_digest,
        }
        return type_map.get(notification_type, True)
    
    async def _console_notify(
        self,
        notification_type: NotificationType,
        title: str,
        message: str,
        data: Optional[Dict[str, Any]] = None,
    ):
        """æ§åˆ¶å°é€šçŸ¥"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"\n{'='*60}")
        print(f"ğŸ“¢ [{timestamp}] {notification_type.value.upper()}")
        print(f"   {title}")
        print(f"   {message}")
        if data:
            print(f"   è¯¦æƒ…: {data}")
        print(f"{'='*60}\n")


class CollectionStorage:
    """æ”¶å½•æ•°æ®å­˜å‚¨"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self._records_file = self.data_dir / "collection_records.json"
        self._state_file = self.data_dir / "scheduler_state.json"
        
        self._records: Dict[str, CollectionRecord] = {}
        self._load_records()
    
    def _load_records(self):
        """åŠ è½½æ”¶å½•è®°å½•"""
        if self._records_file.exists():
            try:
                with open(self._records_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for key, record_data in data.items():
                        self._records[key] = CollectionRecord.from_dict(record_data)
            except Exception as e:
                print(f"Error loading collection records: {e}")
    
    def _save_records(self):
        """ä¿å­˜æ”¶å½•è®°å½•"""
        try:
            data = {k: v.to_dict() for k, v in self._records.items()}
            with open(self._records_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Error saving collection records: {e}")
    
    def _make_key(self, paper_id: str, scholar_id: str) -> str:
        """ç”Ÿæˆè®°å½•é”®"""
        return f"{scholar_id}:{paper_id}"
    
    def add_record(self, record: CollectionRecord):
        """æ·»åŠ æ”¶å½•è®°å½•"""
        key = self._make_key(record.paper_id, record.scholar_id)
        self._records[key] = record
        self._save_records()
    
    def get_record(self, paper_id: str, scholar_id: str) -> Optional[CollectionRecord]:
        """è·å–æ”¶å½•è®°å½•"""
        key = self._make_key(paper_id, scholar_id)
        return self._records.get(key)
    
    def has_record(self, paper_id: str, scholar_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²æ”¶å½•"""
        key = self._make_key(paper_id, scholar_id)
        return key in self._records
    
    def get_records_by_scholar(self, scholar_id: str) -> List[CollectionRecord]:
        """è·å–å­¦è€…çš„æ‰€æœ‰æ”¶å½•è®°å½•"""
        return [
            r for r in self._records.values()
            if r.scholar_id == scholar_id
        ]
    
    def get_recent_records(self, days: int = 7) -> List[CollectionRecord]:
        """è·å–æœ€è¿‘çš„æ”¶å½•è®°å½•"""
        cutoff = datetime.now() - timedelta(days=days)
        return [
            r for r in self._records.values()
            if r.collected_at >= cutoff
        ]
    
    def save_state(self, state: Dict[str, Any]):
        """ä¿å­˜è°ƒåº¦å™¨çŠ¶æ€"""
        try:
            with open(self._state_file, 'w', encoding='utf-8') as f:
                json.dump(state, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Error saving scheduler state: {e}")
    
    def load_state(self) -> Dict[str, Any]:
        """åŠ è½½è°ƒåº¦å™¨çŠ¶æ€"""
        if self._state_file.exists():
            try:
                with open(self._state_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"Error loading scheduler state: {e}")
        return {}


class PaperCollector:
    """
    è®ºæ–‡æ”¶å½•å™¨
    
    å€Ÿé‰´ JobLeap çš„ä¿¡æ¯æ”¶å½•æœºåˆ¶:
    - å®šæœŸä»æ•°æ®æºæ”¶å½•æ–°ä¿¡æ¯
    - æ ‡æ³¨æ”¶å½•æ—¶é—´
    - å»é‡å¤„ç†
    - å˜æ›´æ£€æµ‹
    """
    
    def __init__(
        self,
        config: SchedulerConfig,
        paper_fetcher: Optional[Callable[[str], Awaitable[List[PaperMeta]]]] = None,
    ):
        self.config = config
        self.storage = CollectionStorage(config.data_dir)
        self.notification = NotificationHandler(config.notification)
        self.feed_service = ScholarFeedService()
        
        # è®ºæ–‡è·å–å‡½æ•°ï¼ˆéœ€è¦å¤–éƒ¨æ³¨å…¥ï¼‰
        self._paper_fetcher = paper_fetcher
        
        # è¿½è¸ªçš„å­¦è€…
        self._tracked_scholars: Dict[str, Scholar] = {}
        
        # ä¸Šæ¬¡å¼•ç”¨è®¡æ•°ç¼“å­˜ï¼ˆç”¨äºæ£€æµ‹å˜åŒ–ï¼‰
        self._citation_cache: Dict[str, int] = {}
    
    def set_paper_fetcher(self, fetcher: Callable[[str], Awaitable[List[PaperMeta]]]):
        """è®¾ç½®è®ºæ–‡è·å–å‡½æ•°"""
        self._paper_fetcher = fetcher
    
    def track_scholar(self, scholar: Scholar):
        """æ·»åŠ è¿½è¸ªå­¦è€…"""
        self._tracked_scholars[scholar.semantic_scholar_id] = scholar
        self.feed_service.track_scholar(scholar)
    
    def untrack_scholar(self, scholar_id: str):
        """å–æ¶ˆè¿½è¸ªå­¦è€…"""
        self._tracked_scholars.pop(scholar_id, None)
        self.feed_service.untrack_scholar(scholar_id)
    
    async def collect_for_scholar(self, scholar: Scholar) -> List[PaperMeta]:
        """
        æ”¶å½•å­¦è€…çš„è®ºæ–‡
        
        Returns:
            æ–°æ”¶å½•çš„è®ºæ–‡åˆ—è¡¨
        """
        if not self._paper_fetcher:
            print(f"Warning: No paper fetcher configured")
            return []
        
        try:
            # è·å–è®ºæ–‡
            papers = await self._paper_fetcher(scholar.semantic_scholar_id)
            
            new_papers = []
            for paper in papers[:self.config.max_papers_per_scholar]:
                # æ£€æŸ¥æ˜¯å¦å·²æ”¶å½•
                if self.storage.has_record(paper.paper_id, scholar.semantic_scholar_id):
                    # æ£€æŸ¥å¼•ç”¨å˜åŒ–
                    await self._check_citation_change(scholar, paper)
                    continue
                
                # åˆ›å»ºæ”¶å½•è®°å½•
                record = CollectionRecord(
                    paper_id=paper.paper_id,
                    scholar_id=scholar.semantic_scholar_id,
                    collected_at=datetime.now(),
                    citation_count_at_collection=paper.citation_count,
                    metadata={
                        "title": paper.title,
                        "venue": paper.venue,
                        "year": paper.year,
                    }
                )
                
                self.storage.add_record(record)
                new_papers.append(paper)
                
                # æ›´æ–°å¼•ç”¨ç¼“å­˜
                self._citation_cache[paper.paper_id] = paper.citation_count
                
                # æ·»åŠ åˆ°ä¿¡æ¯æµ
                self.feed_service.process_new_papers(scholar, [paper])
                
                # å‘é€é€šçŸ¥
                await self.notification.notify(
                    NotificationType.NEW_PAPER,
                    f"ğŸ†• {scholar.name} çš„æ–°è®ºæ–‡",
                    f"{paper.title} ({paper.venue or 'Unknown'}, {paper.year or 'N/A'})",
                    {"paper_id": paper.paper_id, "citations": paper.citation_count}
                )
            
            return new_papers
            
        except Exception as e:
            print(f"Error collecting papers for {scholar.name}: {e}")
            return []
    
    async def _check_citation_change(self, scholar: Scholar, paper: PaperMeta):
        """æ£€æŸ¥å¼•ç”¨å˜åŒ–"""
        old_count = self._citation_cache.get(paper.paper_id)
        
        if old_count is not None and paper.citation_count != old_count:
            # æ›´æ–°ç¼“å­˜
            self._citation_cache[paper.paper_id] = paper.citation_count
            
            # æ·»åŠ åˆ°ä¿¡æ¯æµ
            self.feed_service.process_citation_changes(scholar, paper, old_count)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é‡Œç¨‹ç¢‘
            for milestone in self.config.notification.citation_milestones:
                if old_count < milestone <= paper.citation_count:
                    await self.notification.notify(
                        NotificationType.CITATION_MILESTONE,
                        f"ğŸ‰ å¼•ç”¨é‡Œç¨‹ç¢‘: {milestone}",
                        f"ã€Š{paper.title}ã€‹è¾¾åˆ° {paper.citation_count} æ¬¡å¼•ç”¨ï¼",
                        {"paper_id": paper.paper_id, "milestone": milestone}
                    )
                    break
    
    async def collect_all(self) -> Dict[str, List[PaperMeta]]:
        """æ”¶å½•æ‰€æœ‰è¿½è¸ªå­¦è€…çš„è®ºæ–‡"""
        results = {}
        
        for scholar_id, scholar in self._tracked_scholars.items():
            papers = await self.collect_for_scholar(scholar)
            results[scholar_id] = papers
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            await asyncio.sleep(1)
        
        return results
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """è·å–æ”¶å½•ç»Ÿè®¡"""
        recent_records = self.storage.get_recent_records(days=7)
        
        return {
            "tracked_scholars": len(self._tracked_scholars),
            "total_records": len(self.storage._records),
            "records_last_7_days": len(recent_records),
            "papers_by_scholar": {
                scholar_id: len(self.storage.get_records_by_scholar(scholar_id))
                for scholar_id in self._tracked_scholars
            }
        }


class Scheduler:
    """
    è°ƒåº¦å™¨ä¸»ç±»
    
    ç®¡ç†å®šæ—¶æ”¶å½•ä»»åŠ¡
    """
    
    def __init__(self, config: SchedulerConfig = None):
        self.config = config or SchedulerConfig()
        self.collector = PaperCollector(self.config)
        self.storage = CollectionStorage(self.config.data_dir)
        
        self._running = False
        self._last_collection: Optional[datetime] = None
        self._task: Optional[asyncio.Task] = None
    
    def set_paper_fetcher(self, fetcher: Callable[[str], Awaitable[List[PaperMeta]]]):
        """è®¾ç½®è®ºæ–‡è·å–å‡½æ•°"""
        self.collector.set_paper_fetcher(fetcher)
    
    def track_scholar(self, scholar: Scholar):
        """æ·»åŠ è¿½è¸ªå­¦è€…"""
        self.collector.track_scholar(scholar)
    
    def track_scholars(self, scholars: List[Scholar]):
        """æ‰¹é‡æ·»åŠ è¿½è¸ªå­¦è€…"""
        for scholar in scholars:
            self.track_scholar(scholar)
    
    def get_interval_seconds(self) -> int:
        """è·å–æ”¶å½•é—´éš”ï¼ˆç§’ï¼‰"""
        if self.config.collection_interval == CollectionInterval.CUSTOM:
            return self.config.custom_interval_seconds
        return self.config.collection_interval.value
    
    async def run_once(self) -> Dict[str, List[PaperMeta]]:
        """æ‰§è¡Œä¸€æ¬¡æ”¶å½•"""
        print(f"[{datetime.now()}] Starting collection...")
        
        results = await self.collector.collect_all()
        
        self._last_collection = datetime.now()
        self._save_state()
        
        # ç»Ÿè®¡
        total_new = sum(len(papers) for papers in results.values())
        print(f"[{datetime.now()}] Collection complete. New papers: {total_new}")
        
        return results
    
    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self._running:
            print("Scheduler is already running")
            return
        
        self._running = True
        self._load_state()
        
        print(f"Scheduler started. Interval: {self.get_interval_seconds()}s")
        
        # å¯åŠ¨åå°ä»»åŠ¡
        self._task = asyncio.create_task(self._run_loop())
    
    async def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self._running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        
        self._save_state()
        print("Scheduler stopped")
    
    async def _run_loop(self):
        """è°ƒåº¦å¾ªç¯"""
        while self._running:
            try:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œæ”¶å½•
                if self._should_collect():
                    await self.run_once()
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"Scheduler error: {e}")
                await asyncio.sleep(self.config.retry_delay_seconds)
    
    def _should_collect(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œæ”¶å½•"""
        if self._last_collection is None:
            return True
        
        elapsed = (datetime.now() - self._last_collection).total_seconds()
        return elapsed >= self.get_interval_seconds()
    
    def _save_state(self):
        """ä¿å­˜çŠ¶æ€"""
        state = {
            "last_collection": self._last_collection.isoformat() if self._last_collection else None,
            "tracked_scholars": list(self.collector._tracked_scholars.keys()),
        }
        self.storage.save_state(state)
    
    def _load_state(self):
        """åŠ è½½çŠ¶æ€"""
        state = self.storage.load_state()
        if state.get("last_collection"):
            self._last_collection = datetime.fromisoformat(state["last_collection"])
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        return {
            "running": self._running,
            "last_collection": self._last_collection.isoformat() if self._last_collection else None,
            "next_collection_in": self._get_next_collection_time(),
            "collection_stats": self.collector.get_collection_stats(),
        }
    
    def _get_next_collection_time(self) -> Optional[str]:
        """è·å–ä¸‹æ¬¡æ”¶å½•æ—¶é—´"""
        if not self._last_collection:
            return "Immediately"
        
        next_time = self._last_collection + timedelta(seconds=self.get_interval_seconds())
        if next_time <= datetime.now():
            return "Pending"
        
        remaining = (next_time - datetime.now()).total_seconds()
        if remaining < 60:
            return f"{int(remaining)}s"
        elif remaining < 3600:
            return f"{int(remaining / 60)}m"
        else:
            return f"{int(remaining / 3600)}h"
    
    def get_feed(self, limit: int = 20) -> str:
        """è·å–ä¿¡æ¯æµ"""
        return self.collector.feed_service.get_feed_formatted(limit)


class ConferenceTracker:
    """
    ä¼šè®®è¿½è¸ªå™¨
    
    è¿½è¸ªé‡è¦ä¼šè®®çš„æˆªæ­¢æ—¥æœŸå¹¶å‘é€æé†’
    """
    
    def __init__(self, notification: NotificationHandler):
        self.notification = notification
        self._conferences: Dict[str, Dict[str, Any]] = {}
    
    def add_conference(
        self,
        name: str,
        deadline: datetime,
        url: Optional[str] = None,
        remind_days_before: List[int] = None,
    ):
        """æ·»åŠ ä¼šè®®"""
        self._conferences[name] = {
            "name": name,
            "deadline": deadline,
            "url": url,
            "remind_days_before": remind_days_before or [7, 3, 1],
            "reminded": set(),
        }
    
    async def check_deadlines(self):
        """æ£€æŸ¥æˆªæ­¢æ—¥æœŸ"""
        now = datetime.now()
        
        for name, conf in self._conferences.items():
            deadline = conf["deadline"]
            days_left = (deadline - now).days
            
            for remind_day in conf["remind_days_before"]:
                if days_left <= remind_day and remind_day not in conf["reminded"]:
                    await self.notification.notify(
                        NotificationType.CONFERENCE_DEADLINE,
                        f"â° {name} æˆªæ­¢æé†’",
                        f"è·ç¦»æˆªæ­¢æ—¥æœŸè¿˜æœ‰ {days_left} å¤©ï¼",
                        {"deadline": deadline.isoformat(), "url": conf.get("url")}
                    )
                    conf["reminded"].add(remind_day)
    
    def get_upcoming_conferences(self, days: int = 30) -> List[Dict[str, Any]]:
        """è·å–å³å°†åˆ°æ¥çš„ä¼šè®®"""
        now = datetime.now()
        cutoff = now + timedelta(days=days)
        
        upcoming = []
        for name, conf in self._conferences.items():
            if now <= conf["deadline"] <= cutoff:
                days_left = (conf["deadline"] - now).days
                upcoming.append({
                    "name": name,
                    "deadline": conf["deadline"].isoformat(),
                    "days_left": days_left,
                    "url": conf.get("url"),
                })
        
        return sorted(upcoming, key=lambda x: x["days_left"])


# ä¾¿æ·å‡½æ•°
def create_scheduler(
    interval: str = "daily",
    data_dir: str = "./data/scheduler",
    notify_console: bool = True,
) -> Scheduler:
    """
    åˆ›å»ºè°ƒåº¦å™¨
    
    Args:
        interval: "hourly", "daily", "weekly"
        data_dir: æ•°æ®å­˜å‚¨ç›®å½•
        notify_console: æ˜¯å¦å¯ç”¨æ§åˆ¶å°é€šçŸ¥
    
    Returns:
        é…ç½®å¥½çš„è°ƒåº¦å™¨
    """
    interval_map = {
        "hourly": CollectionInterval.HOURLY,
        "daily": CollectionInterval.DAILY,
        "weekly": CollectionInterval.WEEKLY,
    }
    
    config = SchedulerConfig(
        collection_interval=interval_map.get(interval, CollectionInterval.DAILY),
        data_dir=data_dir,
        notification=NotificationConfig(
            enabled=True,
            channels=["console"] if notify_console else [],
        ),
    )
    
    return Scheduler(config)
