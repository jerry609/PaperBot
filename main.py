#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SecuriPaperBot - ä¸»å¯åŠ¨è„šæœ¬
ä¸€ä¸ªç®€åŒ–çš„å¯åŠ¨å…¥å£ï¼Œé¿å…å¤æ‚çš„åŒ…å¯¼å…¥é—®é¢˜
"""

import sys
import os
import argparse
import asyncio
import time
from pathlib import Path
from typing import Optional
import logging

# è§£å†³ Windows ä¸Š curl_cffi çš„å…¼å®¹æ€§é—®é¢˜
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œè§£å†³å¯¼å…¥é—®é¢˜
current_dir = Path(__file__).parent.absolute()
sys.path.insert(0, str(current_dir))

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    if sys.version_info < (3, 8):
        print(f"âŒ é”™è¯¯: éœ€è¦Python 3.8+ï¼Œå½“å‰ç‰ˆæœ¬: {sys.version}")
            # å¼‚æ­¥æ‰§è¡Œä¸‹è½½ï¼ˆä¸å…¶ä»–ä¼šè®®ç›¸åŒçš„é€»è¾‘ï¼‰
        return False
    return True

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    required_packages = [
        'requests', 'lxml', 'urllib3', 'aiohttp', 'bs4'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘å¿…è¦ä¾èµ–: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    return True



async def _sequential_download(downloader, valid_papers):
    """é¡ºåºä¸‹è½½è®ºæ–‡å¹¶æ˜¾ç¤ºè¿›åº¦"""
    download_results = []
    success_count = 0
    cached_count = 0
    start_time = time.time()

    print(f"ğŸ“„ å¼€å§‹é€ä¸ªä¸‹è½½ {len(valid_papers)} ç¯‡è®ºæ–‡")

    for idx, paper in enumerate(valid_papers):
        paper_start_time = time.time()
        try:
            result = await downloader.download_paper(
                paper['url'],
                paper.get('title', f'paper_{idx}'),
                paper_index=idx,
                total_papers=len(valid_papers)
            )
            paper_time = time.time() - paper_start_time

            if result and result.get('success'):
                if result.get('cached'):
                    print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­ (è€—æ—¶: {paper_time:.1f}s)")
                    cached_count += 1
                else:
                    size_kb = result.get('size', 0) / 1024
                    print(f"âœ… ä¸‹è½½æˆåŠŸ (è€—æ—¶: {paper_time:.1f}s, å¤§å°: {size_kb:.1f}KB)")
                success_count += 1
                download_results.append(result)
            else:
                error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯') if result else 'ä¸‹è½½å¤±è´¥'
                print(f"âŒ ä¸‹è½½å¤±è´¥: {error_msg}")
                download_results.append(result or {'success': False})

            if idx < len(valid_papers) - 1:
                await asyncio.sleep(2)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹

        except Exception as e:
            print(f"âŒ ä¸‹è½½å¼‚å¸¸: {str(e)}")
            download_results.append({'success': False, 'error': str(e)})

    total_time = time.time() - start_time
    print("\n" + "ğŸ‰ ä¸‹è½½å®Œæˆç»Ÿè®¡:")
    print(f"âœ… æˆåŠŸä¸‹è½½: {success_count}/{len(download_results)} ç¯‡è®ºæ–‡")
    print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­: {cached_count} ç¯‡")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
    print(f"ğŸ“ æ–‡ä»¶å­˜å‚¨åœ¨: {downloader.download_path}")

    if success_count > 0:
        avg_time = total_time / success_count
        print(f"ğŸ“Š å¹³å‡é€Ÿåº¦: {avg_time:.2f} ç§’/ç¯‡")

    success_rate = (success_count / len(valid_papers)) if valid_papers else 0
    print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1%}")


def simple_paper_download(conference: str, year: str, url: Optional[str] = None, smart_mode: bool = False):
    """
    ç®€åŒ–çš„è®ºæ–‡ä¸‹è½½åŠŸèƒ½ï¼Œæ ¹æ®ä¼šè®®ç±»å‹é€‰æ‹©åˆé€‚çš„ä¸‹è½½å™¨ã€‚
    - CCSä¼šè®®ä½¿ç”¨ä¸“ç”¨çš„ `downloader_ccs`ã€‚
    - å…¶ä»–ä¼šè®®ä½¿ç”¨é€šç”¨çš„ `downloader`ï¼Œå¹¶æ”¯æŒæ™ºèƒ½å¹¶å‘æ¨¡å¼ã€‚
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {conference.upper()} {year} å¹´è®ºæ–‡...")

    is_ccs = conference.lower() == 'ccs'
    
    # æ ¹æ®ä¼šè®®ç±»å‹é€‰æ‹©ä¸‹è½½å™¨
    if is_ccs:
        from utils.downloader_ccs import PaperDownloader as DownloaderClass
        print("ğŸ“š ç›®æ ‡ä¼šè®®: CCS (ä½¿ç”¨ä¸“ç”¨è§£æé€»è¾‘)")
        if smart_mode:
            print("â„¹ï¸  CCS ä¸‹è½½ç›®å‰ä¸æ”¯æŒæ™ºèƒ½æ¨¡å¼ï¼Œå°†ä½¿ç”¨ç¨³å®šé¡ºåºæ¨¡å¼ã€‚")
            smart_mode = False  # å¼ºåˆ¶ä¸ºé¡ºåºæ¨¡å¼
    else:
    from agents.conference_research_agent import ConferenceResearchAgent

    async def _run_download():
        try:
            agent = ConferenceResearchAgent({"download_path": f'./papers/{conference}_{year}'})
            result = await agent.process(conference, year)
            papers = result.get("papers", [])
            print(f"âœ… æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
            with_pdf = [p for p in papers if p.get("local_path")]
            print(f"ğŸ“ ä¸‹è½½æˆåŠŸ {len(with_pdf)} ç¯‡ï¼›å«ä»£ç é“¾æ¥ {sum(1 for p in papers if p.get('github_links'))}")
        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°ä¸¥é‡é”™è¯¯: {e}")

    try:
        asyncio.run(_run_download())
        print("âœ… ä¸‹è½½ä»»åŠ¡å®Œæˆ")
    except Exception as e:
        print(f"âŒ å¼‚æ­¥æ‰§è¡Œå¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ‚¨æœ‰ç½‘ç»œè®¿é—®æƒé™å’Œæ­£ç¡®çš„ä¼šè®®ä¿¡æ¯ã€‚")
        
def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ§åˆ¶å°ç¼–ç ï¼Œé˜²æ­¢ä¸­æ–‡ä¹±ç 
    import sys
    import io
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

    # å…¨å±€æ—¶åŒº/seed/æ—¥å¿—
    os.environ.setdefault("TZ", "UTC")
    try:
        time.tzset()
    except Exception:
        pass
    seed = int(os.getenv("PAPERBOT_SEED", "42"))
    try:
        import random
        random.seed(seed)
        import numpy as np
        np.random.seed(seed)
    except Exception:
        pass
    logging.basicConfig(
        level=os.getenv("PAPERBOT_LOG_LEVEL", "INFO"),
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    print("=" * 60)
    print("ğŸ” SecuriPaperBot - æ™ºèƒ½è®ºæ–‡åˆ†ææ¡†æ¶")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_python_version():
        sys.exit(1)
    
    parser = argparse.ArgumentParser(description="SecuriPaperBot - æ™ºèƒ½è®ºæ–‡åˆ†æå·¥å…·")
    
    # æ·»åŠ å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ä¸‹è½½å‘½ä»¤ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
    parser.add_argument('--conference', choices=['ccs', 'sp', 'ndss', 'usenix'], 
                       help='ä¼šè®®åç§°')
    parser.add_argument('--year', help='ä¼šè®®å¹´ä»½ (ä¾‹å¦‚: 23 è¡¨ç¤º2023å¹´)')
    parser.add_argument('--url', help='æœºæ„ACMè®¿é—®URL')
    parser.add_argument('--check', action='store_true', help='æ£€æŸ¥ç¯å¢ƒé…ç½®')
    parser.add_argument('--demo', action='store_true', help='è¿è¡Œæ¼”ç¤ºæ¨¡å¼')
    parser.add_argument('--smart', action='store_true', help='æ˜ç¡®å¯ç”¨æ™ºèƒ½å¹¶å‘ä¸‹è½½æ¨¡å¼')
    parser.add_argument('--no-smart', action='store_true', help='ç¦ç”¨æ™ºèƒ½æ¨¡å¼ï¼Œä½¿ç”¨ä¼ ç»Ÿç¨³å®šæ¨¡å¼')
    
    # å­¦è€…è¿½è¸ªå‘½ä»¤
    track_parser = subparsers.add_parser('track', help='å­¦è€…è¿½è¸ªåŠŸèƒ½')
    track_parser.add_argument('--config', type=str, 
                              default='config/scholar_subscriptions.yaml',
                              help='è®¢é˜…é…ç½®æ–‡ä»¶è·¯å¾„')
    track_parser.add_argument('--scholar-id', type=str, 
                              help='ä»…è¿½è¸ªæŒ‡å®šå­¦è€… (Semantic Scholar ID)')
    track_parser.add_argument('--force', action='store_true',
                              help='å¼ºåˆ¶é‡æ–°æ£€æµ‹ï¼ˆæ¸…é™¤ç¼“å­˜ï¼‰')
    track_parser.add_argument('--dry-run', action='store_true',
                              help='ä»…æ£€æµ‹æ–°è®ºæ–‡ï¼Œä¸ç”ŸæˆæŠ¥å‘Š')
    track_parser.add_argument('--summary', action='store_true',
                              help='æ˜¾ç¤ºè¿½è¸ªçŠ¶æ€æ‘˜è¦')
    track_parser.add_argument('--dataset-path', type=str,
                               help='æœ¬åœ°æ•°æ®é›†è·¯å¾„ï¼ˆè¦†ç›– data_source.dataset_pathï¼‰')
    track_parser.add_argument('--repro', action='store_true',
                               help='å¯ç”¨å¯å¤ç°æ€§éªŒè¯ï¼ˆéœ€ Dockerï¼‰')

    # è¿è¡Œå®éªŒï¼ˆExperimentManagerï¼‰
    exp_parser = subparsers.add_parser('run-exp', help='è¿è¡Œå®éªŒé…ç½® (ExperimentManager)')
    exp_parser.add_argument('--config', required=True, help='å®éªŒé…ç½®æ–‡ä»¶è·¯å¾„ (YAML)')

    # æ¸²æŸ“æŠ¥å‘Šï¼ˆä» meta.json + æ¨¡æ¿ï¼‰
    render_parser = subparsers.add_parser('render-report', help='æ ¹æ® meta.json æ¸²æŸ“æŠ¥å‘Š')
    render_parser.add_argument('--meta', required=False, help='pipeline/å®éªŒç”Ÿæˆçš„ meta.json è·¯å¾„ï¼Œç¼ºçœè‡ªåŠ¨é€‰æœ€æ–°')
    render_parser.add_argument('--template', default=None, help='æŠ¥å‘Šæ¨¡æ¿åç§°ï¼Œé»˜è®¤ä½¿ç”¨ meta æˆ– settings ä¸­é…ç½®')
    render_parser.add_argument('--output', default=None, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤æŒ‰è®ºæ–‡IDå‘½åå†™å…¥é»˜è®¤ç›®å½•ï¼‰')
    
    parser.add_argument('--mode', choices=['production', 'academic'], default=os.getenv("PAPERBOT_MODE", "production"),
                       help='è¿è¡Œæ¨¡å¼ (production/academic)')
    parser.add_argument('--report-template', dest='report_template', default=None,
                       help='è¦†ç›–æŠ¥å‘Šæ¨¡æ¿åç§° (å¦‚ paper_report.md.j2 / academic_report.md.j2)')
    parser.add_argument('--data-source', dest='data_source', default=None,
                       help='æ•°æ®æºç±»å‹è¦†ç›– (api/local/hybrid)ï¼Œlocal æ—¶éœ€é…åˆ dataset_path/dataset_name')

    args = parser.parse_args()
    
    if args.check:
        print("ğŸ” æ£€æŸ¥ç¯å¢ƒé…ç½®...")
        deps_ok = check_dependencies()
        if deps_ok:
            print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        else:
            print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return
    
    if args.demo:
        print("ğŸ¯ è¿è¡Œæ¼”ç¤ºæ¨¡å¼...")
        print("ğŸ“‹ æ”¯æŒçš„åŠŸèƒ½:")
        print("  - ACM CCS è®ºæ–‡ä¸‹è½½")
        print("  - IEEE S&P è®ºæ–‡ä¸‹è½½")
        print("  - NDSS è®ºæ–‡ä¸‹è½½")
        print("  - USENIX Security è®ºæ–‡ä¸‹è½½")
        print("  - è®ºæ–‡ä»£ç é“¾æ¥æå–")
        print("  - ä»£ç è´¨é‡åˆ†æ")
        print("  - æ–‡æ¡£ç”Ÿæˆ")
        print("ğŸ’¡ æ‰€æœ‰åŠŸèƒ½å®Œå…¨å¯ç”¨!")
        return
    
    if not check_dependencies():
        print("\nğŸ“¦ å®‰è£…ä¾èµ–:")
        print("pip install requests lxml urllib3 aiohttp beautifulsoup4 pdfplumber")
        sys.exit(1)
    
    # å¤„ç†å­¦è€…è¿½è¸ªå‘½ä»¤
    if args.command == 'track':
        run_scholar_tracking(args)
        return

    # å¤„ç†å®éªŒå‘½ä»¤
    if args.command == 'run-exp':
        run_experiment(args)
        return

    # æ¸²æŸ“æŠ¥å‘Š
    if args.command == 'render-report':
        render_report(args)
        return
    
    if args.conference and args.year:
        # æ‰€æœ‰ä¼šè®®ä½¿ç”¨ç›¸åŒçš„ä¸‹è½½é€»è¾‘
        if args.no_smart:
            smart_mode = False  # æ˜ç¡®ç¦ç”¨æ™ºèƒ½æ¨¡å¼
        elif args.smart:
            smart_mode = True   # æ˜ç¡®å¯ç”¨æ™ºèƒ½æ¨¡å¼
        else:
            smart_mode = True   # é»˜è®¤å¯ç”¨æ™ºèƒ½æ¨¡å¼
        
        mode_desc = "æ™ºèƒ½åŠ é€Ÿæ¨¡å¼" if smart_mode else "ä¼ ç»Ÿç¨³å®šæ¨¡å¼"
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {args.conference.upper()} {args.year} è®ºæ–‡ ({mode_desc})...")
        simple_paper_download(args.conference, args.year, args.url, smart_mode)
    else:
        print("ğŸ“ ä½¿ç”¨å¸®åŠ©:")
        print("  æ£€æŸ¥ç¯å¢ƒ: python main.py --check")
        print("  æŸ¥çœ‹æ¼”ç¤º: python main.py --demo")
        print("  ä¸‹è½½è®ºæ–‡ (é»˜è®¤æ™ºèƒ½æ¨¡å¼):")
        print("    CCS:    python main.py --conference ccs --year 23")
        print("    S&P:    python main.py --conference sp --year 23")
        print("    NDSS:   python main.py --conference ndss --year 23")
        print("    USENIX: python main.py --conference usenix --year 23")
        print("  å…³é—­æ™ºèƒ½æ¨¡å¼ (ä¼ ç»Ÿç¨³å®šæ¨¡å¼):")
        print("    python main.py --conference ndss --year 23 --no-smart")
        print("  å­¦è€…è¿½è¸ª:")
        print("    python main.py track --summary")
        print("    python main.py track")
        print("    python main.py track --scholar-id 1741101")
        print("    python main.py track --force")
        print("  æŸ¥çœ‹å¸®åŠ©: python main.py --help")
        print("ğŸ’¡ æ³¨æ„: æ‰€æœ‰ä¼šè®®éƒ½ä½¿ç”¨ç›¸åŒçš„ä¸‹è½½æ–¹å¼ï¼Œæ”¯æŒä¸åŒå¹´ä»½")
        print("ğŸ¤– æ™ºèƒ½æ¨¡å¼é»˜è®¤å¯ç”¨ï¼Œæä¾›æ›´å¿«çš„ä¸‹è½½é€Ÿåº¦å’Œè¿›åº¦æ˜¾ç¤º")


def run_experiment(args):
    """è¿è¡Œ ExperimentManager å®éªŒ"""
    from ExperimentManager.runner import ExperimentRunner

    cfg_path = Path(args.config).expanduser()
    if not cfg_path.is_absolute():
        cfg_path = current_dir / cfg_path
    cfg_path = cfg_path.resolve()
    if not cfg_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°å®éªŒé…ç½®æ–‡ä»¶: {cfg_path}")
        return

    print(f"ğŸ§ª è¿è¡Œå®éªŒ: {cfg_path}")
    runner = ExperimentRunner(str(cfg_path))
    runner.run()
    print("âœ… å®éªŒå®Œæˆï¼Œç»“æœå·²å†™å…¥ output/experiments")


def render_report(args):
    """æ ¹æ® meta.json æ¸²æŸ“æŠ¥å‘Šï¼ˆpaper/academic æ¨¡æ¿å…¼å®¹ï¼‰"""
    import json
    from config.settings import settings
    from reports.writer import ReportWriter
    from scholar_tracking.models import PaperMeta
    from scholar_tracking.models.influence import InfluenceResult
    from pathlib import Path
    import glob

    meta_path = None
    if args.meta:
        candidate = Path(args.meta).expanduser()
        if not candidate.is_absolute():
            candidate = current_dir / candidate
        if candidate.exists():
            meta_path = candidate.resolve()
    else:
        # è‡ªåŠ¨å‘ç° output/experiments ä¸‹æœ€æ–° *_meta.json
        pattern = current_dir / "output" / "experiments" / "*_meta.json"
        metas = glob.glob(str(pattern))
        if metas:
            metas.sort(key=lambda p: Path(p).stat().st_mtime, reverse=True)
            meta_path = Path(metas[0]).resolve()

    if not meta_path or not meta_path.exists():
        print("âŒ æ‰¾ä¸åˆ° meta æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ --meta æŒ‡å®šæˆ–ç¡®ä¿ output/experiments ä¸‹å­˜åœ¨ *_meta.json")
        return

    try:
        meta = json.loads(meta_path.read_text(encoding="utf-8"))
    except Exception as e:
        print(f"âŒ è¯»å– meta å¤±è´¥: {e}")
        return

    # å…¼å®¹ä¸åŒå­—æ®µå‘½å
    paper_dict = meta.get("paper") or meta.get("paper_meta") or {}
    influence_dict = meta.get("influence") or meta.get("influence_result") or meta.get("results_summary", [{}])[0].get("influence", {})
    research = meta.get("research") or meta.get("research_result") or {}
    code_analysis = meta.get("code_analysis") or meta.get("code_analysis_result") or {}
    quality = meta.get("quality") or meta.get("quality_result") or {}
    scholar_name = meta.get("scholar_name") or meta.get("scholar") or None

    try:
        paper = PaperMeta.from_dict(paper_dict)
    except Exception as e:
        print(f"âŒ æ„é€  PaperMeta å¤±è´¥: {e}")
        return

    if not influence_dict:
        # æœ€å°å…œåº•ï¼Œé¿å…æ¨¡æ¿å´©æºƒ
        influence_dict = {
            "total_score": 0.0,
            "academic_score": 0.0,
            "engineering_score": 0.0,
            "explanation": "No influence data provided.",
            "metrics_breakdown": {},
            "recommendation": "ä½ä¼˜å…ˆçº§",
        }
    influence = InfluenceResult.from_dict(influence_dict)

    template_name = (
        args.template
        or meta.get("template")
        or settings.report.get("template", "paper_report.md.j2")
    )

    writer = ReportWriter(template_name=template_name)
    md = writer.render_template(
        paper=paper,
        influence=influence,
        research_result=research,
        code_analysis_result=code_analysis,
        quality_result=quality,
        scholar_name=scholar_name,
    )

    # è¿½åŠ å¤ç°ä¿¡æ¯ï¼ˆè‹¥ meta æä¾›ï¼‰
    reproducibility_lines = []
    if meta.get("git_commit") or meta.get("pip_freeze"):
        reproducibility_lines.append("\n\n---\n## å¤ç°ä¿¡æ¯")
        if meta.get("git_commit"):
            reproducibility_lines.append(f"- Git Commit: `{meta['git_commit']}`")
        if meta.get("pip_freeze"):
            reproducibility_lines.append("- ç¯å¢ƒä¾èµ–ï¼ˆæˆªæ–­å±•ç¤ºï¼‰:")
            for line in meta["pip_freeze"][:20]:
                reproducibility_lines.append(f"  - {line}")
    if reproducibility_lines:
        md += "\n".join(reproducibility_lines)

    if args.output:
        out_path = Path(args.output).expanduser()
        if not out_path.is_absolute():
            out_path = current_dir / out_path
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(md, encoding="utf-8")
        print(f"âœ… æŠ¥å‘Šå·²å†™å…¥: {out_path}")
    else:
        path = writer.write_report(md, paper, scholar_name=scholar_name)
        print(f"âœ… æŠ¥å‘Šå·²å†™å…¥: {path}")


def run_scholar_tracking(args):
    """è¿è¡Œå­¦è€…è¿½è¸ªåŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ“š PaperBot å­¦è€…è¿½è¸ªç³»ç»Ÿ")
    print("=" * 60)

    config_path = Path(args.config).expanduser()
    if not config_path.is_absolute():
        config_path = current_dir / config_path
    config_path = config_path.resolve()
    if not config_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è®¢é˜…é…ç½®æ–‡ä»¶: {config_path}")
        return

    async def _run_tracking():
        from scholar_tracking import PaperTrackerAgent, ScholarProfileAgent
        from scholar_tracking.models import PaperMeta
        from core.workflow_coordinator import ScholarWorkflowCoordinator
        from config.settings import settings
        from repro import ReproAgent
        import tempfile, shutil, git

        overrides = {"subscriptions_config_path": str(config_path)}
        mode = getattr(args, "mode", None) or getattr(settings, "mode", "production")
        overrides["mode"] = mode
        if args.report_template:
            overrides["report_template"] = args.report_template
        elif mode == "academic":
            overrides["report_template"] = "academic_report.md.j2"
        if args.data_source:
            overrides["data_source"] = {**settings.data_source, "type": args.data_source}
        if getattr(args, "dataset_path", None):
            ds = overrides.get("data_source", settings.data_source.copy())
            ds["dataset_path"] = args.dataset_path
            overrides["data_source"] = ds
        profile_agent = ScholarProfileAgent(overrides)

        # æ˜¾ç¤ºæ‘˜è¦
        if args.summary:
            print("\nğŸ“Š è¿½è¸ªçŠ¶æ€æ‘˜è¦:")
            print(profile_agent.summary())
            return

        settings = profile_agent.get_settings()
        reporting_cfg = settings.get("reporting", {})
        min_score = settings.get("min_influence_score", 0)

        tracker_agent = PaperTrackerAgent({**overrides, "api": settings.get("api", {}), "data_source": settings.get("data_source", {})})
        coordinator = ScholarWorkflowCoordinator(
            {
                "output_dir": str(profile_agent.get_output_dir()),
                "report_template": reporting_cfg.get("template", overrides.get("report_template", "paper_report.md.j2")),
                "use_documentation_agent": False, # ç¦ç”¨ DocumentationAgent ä»¥é¿å…æ¥å£ä¸åŒ¹é…
                "mode": mode,
            }
        )

        # å¼ºåˆ¶æ¨¡å¼
        if args.force and args.scholar_id:
            print(f"\nğŸ”„ å¼ºåˆ¶é‡æ–°æ£€æµ‹å­¦è€…: {args.scholar_id}")
            profile_agent.clear_scholar_cache(args.scholar_id)
        elif args.force:
            print("\nğŸ”„ æ¸…é™¤æ‰€æœ‰ç¼“å­˜...")
            profile_agent.clear_all_cache()

        # è¿½è¸ªå­¦è€…
        if args.scholar_id:
            scholar = profile_agent.get_scholar_by_id(args.scholar_id)
            if not scholar:
                print(f"âŒ æœªæ‰¾åˆ°å­¦è€…: {args.scholar_id}")
                return
            result = await tracker_agent.track_scholar(scholar, dry_run=args.dry_run)
            results = [result]
            await tracker_agent.ss_agent.close()
        else:
            print("\nğŸ” å¼€å§‹è¿½è¸ªæ‰€æœ‰è®¢é˜…å­¦è€…...")
            results = await tracker_agent.track_all_scholars(dry_run=args.dry_run)

        # æ˜¾ç¤ºç»“æœ
        total_new = 0
        for result in results:
            scholar_name = result.get("scholar_name", "Unknown")
            new_count = result.get("new_papers_count", len(result.get("new_papers", [])))
            status = result.get("status", "unknown")

            if status == "success":
                print(f"  âœ… {scholar_name}: å‘ç° {new_count} ç¯‡æ–°è®ºæ–‡")
                total_new += new_count
            elif status == "error":
                print(f"  âŒ {scholar_name}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"  âš ï¸  {scholar_name}: {status}")

        print(f"\nğŸ“ˆ æ€»è®¡å‘ç° {total_new} ç¯‡æ–°è®ºæ–‡")

        if total_new == 0:
            print("\nâœ… å­¦è€…è¿½è¸ªå®Œæˆ!")
            return

        persist_reports = not args.dry_run
        if args.dry_run:
            print("\nğŸ§ª Dry-Run æ¨¡å¼ï¼šå°†è¿è¡Œåˆ†æä½†ä¸å†™å…¥ Markdown æ–‡ä»¶ã€‚")
        else:
            print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")

        for result in results:
            if result.get("status") != "success":
                continue

            scholar_name = result.get("scholar_name")
            new_papers = result.get("new_papers", [])

            if not new_papers:
                continue

            print(f"\n  å¤„ç† {scholar_name} çš„ {len(new_papers)} ç¯‡è®ºæ–‡...")
            papers = [PaperMeta.from_dict(p) for p in new_papers]
            processed_records = []

            for paper in papers:
                try:
                    report_path, influence, pipeline_data = await coordinator.run_paper_pipeline(
                        paper,
                        scholar_name,
                        persist_report=persist_reports,
                    )

                    pis = f"{influence.total_score:.1f}/100 ({influence.recommendation.value})"
                    if report_path:
                        print(f"    ğŸ“„ {paper.title[:40]}... -> {report_path.name} | PIS {pis}")
                    else:
                        print(f"    ğŸ“„ {paper.title[:40]}... -> (æœªæŒä¹…åŒ–) | PIS {pis}")

                    # å¯å¤ç°æ€§éªŒè¯ï¼ˆéœ€ repoï¼‰
                    repro_result = {}
                    if args.repro and (paper.github_url or paper.has_code):
                        tmp_dir = Path(tempfile.mkdtemp(prefix="paperbot-repro-"))
                        try:
                            repo_url = paper.github_url
                            if repo_url:
                                print(f"    ğŸ” Repro: cloning {repo_url}")
                                git.Repo.clone_from(repo_url, tmp_dir)
                                repro_agent = ReproAgent({"repro": settings.repro})
                                repro_result = await repro_agent.run(tmp_dir)
                            else:
                                repro_result = {"status": "skipped", "reason": "no_repo"}
                        except Exception as e:
                            repro_result = {"status": "error", "error": str(e)}
                            print(f"    âš ï¸ Repro å¤±è´¥: {e}")
                        finally:
                            try:
                                shutil.rmtree(tmp_dir)
                            except Exception:
                                pass

                        # é‡æ–°æ¸²æŸ“æŠ¥å‘Šï¼Œå†™å›
                        try:
                            md = coordinator.report_writer.render_template(
                                paper=paper,
                                influence=influence,
                                research_result=pipeline_data.get("stages", {}).get("research", {}).get("result", {}),
                                code_analysis_result=pipeline_data.get("stages", {}).get("code_analysis", {}).get("result", {}),
                                quality_result=pipeline_data.get("stages", {}).get("quality", {}).get("result", {}),
                                scholar_name=scholar_name,
                                repro_result=repro_result,
                                meta=None,
                            )
                            path = coordinator.report_writer.write_report(md, paper, scholar_name)
                            pipeline_data["report_path"] = str(path)
                        except Exception as e:
                            print(f"    âš ï¸ é‡æ¸²æŸ“æŠ¥å‘Šå¤±è´¥: {e}")

                    processed_records.append(
                        {
                            "paper_id": paper.paper_id,
                            "title": paper.title,
                            "report_path": str(report_path) if report_path else None,
                            "pis": round(influence.total_score, 2),
                            "recommendation": influence.recommendation.value,
                            "status": pipeline_data.get("status", "success"),
                        }
                    )
                except Exception as e:
                    print(f"    âŒ å¤„ç†å¤±è´¥: {paper.title[:40]}... - {e}")
                    processed_records.append(
                        {
                            "paper_id": paper.paper_id,
                            "title": paper.title,
                            "status": f"failed: {e}",
                        }
                    )

            scholar_id = result.get("scholar_id")
            if (
                processed_records
                and scholar_id
                and reporting_cfg.get("persist_history", True)
            ):
                profile_agent.record_processed_papers(
                    scholar_id,
                    processed_records,
                )

        print("\nâœ… å­¦è€…è¿½è¸ªå®Œæˆ!")

    try:
        asyncio.run(_run_tracking())
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è¿½è¸ªè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()