#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SecuriPaperBot - ä¸»å¯åŠ¨è„šæœ¬
ä¸€ä¸ªç®€åŒ–çš„å¯åŠ¨å…¥å£ï¼Œé¿å…å¤æ‚çš„åŒ…å¯¼å…¥é—®é¢˜
"""

import sys
import os
import argparse
import asyncio
import time
from pathlib import Path
from typing import Optional

# è§£å†³ Windows ä¸Š curl_cffi çš„å…¼å®¹æ€§é—®é¢˜
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œè§£å†³å¯¼å…¥é—®é¢˜
current_dir = Path(__file__).parent.absolute()
sys.path.insert(0, str(current_dir))

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    if sys.version_info < (3, 8):
        print(f"âŒ é”™è¯¯: éœ€è¦Python 3.8+ï¼Œå½“å‰ç‰ˆæœ¬: {sys.version}")
            # å¼‚æ­¥æ‰§è¡Œä¸‹è½½ï¼ˆä¸å…¶ä»–ä¼šè®®ç›¸åŒçš„é€»è¾‘ï¼‰
        return False
    return True

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    required_packages = [
        'requests', 'lxml', 'urllib3', 'aiohttp', 'bs4'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘å¿…è¦ä¾èµ–: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    return True



async def _sequential_download(downloader, valid_papers):
    """é¡ºåºä¸‹è½½è®ºæ–‡å¹¶æ˜¾ç¤ºè¿›åº¦"""
    download_results = []
    success_count = 0
    cached_count = 0
    start_time = time.time()

    print(f"ğŸ“„ å¼€å§‹é€ä¸ªä¸‹è½½ {len(valid_papers)} ç¯‡è®ºæ–‡")

    for idx, paper in enumerate(valid_papers):
        paper_start_time = time.time()
        try:
            result = await downloader.download_paper(
                paper['url'],
                paper.get('title', f'paper_{idx}'),
                paper_index=idx,
                total_papers=len(valid_papers)
            )
            paper_time = time.time() - paper_start_time

            if result and result.get('success'):
                if result.get('cached'):
                    print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­ (è€—æ—¶: {paper_time:.1f}s)")
                    cached_count += 1
                else:
                    size_kb = result.get('size', 0) / 1024
                    print(f"âœ… ä¸‹è½½æˆåŠŸ (è€—æ—¶: {paper_time:.1f}s, å¤§å°: {size_kb:.1f}KB)")
                success_count += 1
                download_results.append(result)
            else:
                error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯') if result else 'ä¸‹è½½å¤±è´¥'
                print(f"âŒ ä¸‹è½½å¤±è´¥: {error_msg}")
                download_results.append(result or {'success': False})

            if idx < len(valid_papers) - 1:
                await asyncio.sleep(2)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹

        except Exception as e:
            print(f"âŒ ä¸‹è½½å¼‚å¸¸: {str(e)}")
            download_results.append({'success': False, 'error': str(e)})

    total_time = time.time() - start_time
    print("\n" + "ğŸ‰ ä¸‹è½½å®Œæˆç»Ÿè®¡:")
    print(f"âœ… æˆåŠŸä¸‹è½½: {success_count}/{len(download_results)} ç¯‡è®ºæ–‡")
    print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­: {cached_count} ç¯‡")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
    print(f"ğŸ“ æ–‡ä»¶å­˜å‚¨åœ¨: {downloader.download_path}")

    if success_count > 0:
        avg_time = total_time / success_count
        print(f"ğŸ“Š å¹³å‡é€Ÿåº¦: {avg_time:.2f} ç§’/ç¯‡")

    success_rate = (success_count / len(valid_papers)) if valid_papers else 0
    print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1%}")


def simple_paper_download(conference: str, year: str, url: Optional[str] = None, smart_mode: bool = False):
    """
    ç®€åŒ–çš„è®ºæ–‡ä¸‹è½½åŠŸèƒ½ï¼Œæ ¹æ®ä¼šè®®ç±»å‹é€‰æ‹©åˆé€‚çš„ä¸‹è½½å™¨ã€‚
    - CCSä¼šè®®ä½¿ç”¨ä¸“ç”¨çš„ `downloader_ccs`ã€‚
    - å…¶ä»–ä¼šè®®ä½¿ç”¨é€šç”¨çš„ `downloader`ï¼Œå¹¶æ”¯æŒæ™ºèƒ½å¹¶å‘æ¨¡å¼ã€‚
    """
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {conference.upper()} {year} å¹´è®ºæ–‡...")

    is_ccs = conference.lower() == 'ccs'
    
    # æ ¹æ®ä¼šè®®ç±»å‹é€‰æ‹©ä¸‹è½½å™¨
    if is_ccs:
        from utils.downloader_ccs import PaperDownloader as DownloaderClass
        print("ğŸ“š ç›®æ ‡ä¼šè®®: CCS (ä½¿ç”¨ä¸“ç”¨è§£æé€»è¾‘)")
        if smart_mode:
            print("â„¹ï¸  CCS ä¸‹è½½ç›®å‰ä¸æ”¯æŒæ™ºèƒ½æ¨¡å¼ï¼Œå°†ä½¿ç”¨ç¨³å®šé¡ºåºæ¨¡å¼ã€‚")
            smart_mode = False  # å¼ºåˆ¶ä¸ºé¡ºåºæ¨¡å¼
    else:
        from utils.downloader import PaperDownloader
        from utils.smart_downloader import SmartDownloadManager
        DownloaderClass = PaperDownloader
        print(f"ğŸ“š ç›®æ ‡ä¼šè®®: {conference.upper()}")

    mode_message = "ğŸ¤– ä½¿ç”¨æ™ºèƒ½å¹¶å‘æ¨¡å¼" if smart_mode else "ğŸ”„ ä½¿ç”¨ç¨³å®šé¡ºåºæ¨¡å¼"
    print(mode_message)

    config = {'download_path': f'./papers/{conference}_{year}'}

    async def _run_download():
        downloader_instance = None
        try:
            # åˆå§‹åŒ–ä¸‹è½½å™¨
            if smart_mode and not is_ccs:
                manager = SmartDownloadManager(config)
                downloader_instance = manager.downloader
                papers = await downloader_instance.get_conference_papers(conference, year)
            else:
                # å¯¹äºé¡ºåºæ¨¡å¼æˆ–CCSï¼Œç›´æ¥ä½¿ç”¨ä¸‹è½½å™¨
                downloader_instance = DownloaderClass(config)
                await downloader_instance.__aenter__() # Manually enter context
                papers = await downloader_instance.get_conference_papers(conference, year)

            print(f"âœ… æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
            if not papers:
                print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•è®ºæ–‡ï¼Œè¯·æ£€æŸ¥ä¼šè®®åç§°å’Œå¹´ä»½ã€‚")
                return

            valid_papers = [p for p in papers if isinstance(p.get('url'), str) and p['url'].strip()]
            print(f"ğŸ“ æœ‰æ•ˆPDFé“¾æ¥: {len(valid_papers)}/{len(papers)}")
            if not valid_papers:
                print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„PDFä¸‹è½½é“¾æ¥ã€‚")
                return

            if smart_mode and not is_ccs:
                print("ğŸ¤– å¯åŠ¨æ™ºèƒ½ä¸‹è½½æ¨¡å¼...")
                await manager.download_papers_smart(valid_papers)
            else:
                # æ‰€æœ‰é¡ºåºæ¨¡å¼ï¼ˆåŒ…æ‹¬CCSï¼‰éƒ½ä½¿ç”¨æ­¤è·¯å¾„
                await _sequential_download(downloader_instance, valid_papers)
        
        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
        finally:
            if downloader_instance and not (smart_mode and not is_ccs):
                 await downloader_instance.__aexit__(None, None, None) # Manually exit context


    try:
        asyncio.run(_run_download())
        print("âœ… ä¸‹è½½ä»»åŠ¡å®Œæˆ")
    except Exception as e:
        print(f"âŒ å¼‚æ­¥æ‰§è¡Œå¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ‚¨æœ‰ç½‘ç»œè®¿é—®æƒé™å’Œæ­£ç¡®çš„ä¼šè®®ä¿¡æ¯ã€‚")
        
def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ§åˆ¶å°ç¼–ç ï¼Œé˜²æ­¢ä¸­æ–‡ä¹±ç 
    import sys
    import io
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

    print("=" * 60)
    print("ğŸ” SecuriPaperBot - æ™ºèƒ½è®ºæ–‡åˆ†ææ¡†æ¶")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_python_version():
        sys.exit(1)
    
    parser = argparse.ArgumentParser(description="SecuriPaperBot - æ™ºèƒ½è®ºæ–‡åˆ†æå·¥å…·")
    
    # æ·»åŠ å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ä¸‹è½½å‘½ä»¤ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
    parser.add_argument('--conference', choices=['ccs', 'sp', 'ndss', 'usenix'], 
                       help='ä¼šè®®åç§°')
    parser.add_argument('--year', help='ä¼šè®®å¹´ä»½ (ä¾‹å¦‚: 23 è¡¨ç¤º2023å¹´)')
    parser.add_argument('--url', help='æœºæ„ACMè®¿é—®URL')
    parser.add_argument('--check', action='store_true', help='æ£€æŸ¥ç¯å¢ƒé…ç½®')
    parser.add_argument('--demo', action='store_true', help='è¿è¡Œæ¼”ç¤ºæ¨¡å¼')
    parser.add_argument('--smart', action='store_true', help='æ˜ç¡®å¯ç”¨æ™ºèƒ½å¹¶å‘ä¸‹è½½æ¨¡å¼')
    parser.add_argument('--no-smart', action='store_true', help='ç¦ç”¨æ™ºèƒ½æ¨¡å¼ï¼Œä½¿ç”¨ä¼ ç»Ÿç¨³å®šæ¨¡å¼')
    
    # å­¦è€…è¿½è¸ªå‘½ä»¤
    track_parser = subparsers.add_parser('track', help='å­¦è€…è¿½è¸ªåŠŸèƒ½')
    track_parser.add_argument('--config', type=str, 
                              default='config/scholar_subscriptions.yaml',
                              help='è®¢é˜…é…ç½®æ–‡ä»¶è·¯å¾„')
    track_parser.add_argument('--scholar-id', type=str, 
                              help='ä»…è¿½è¸ªæŒ‡å®šå­¦è€… (Semantic Scholar ID)')
    track_parser.add_argument('--force', action='store_true',
                              help='å¼ºåˆ¶é‡æ–°æ£€æµ‹ï¼ˆæ¸…é™¤ç¼“å­˜ï¼‰')
    track_parser.add_argument('--dry-run', action='store_true',
                              help='ä»…æ£€æµ‹æ–°è®ºæ–‡ï¼Œä¸ç”ŸæˆæŠ¥å‘Š')
    track_parser.add_argument('--summary', action='store_true',
                              help='æ˜¾ç¤ºè¿½è¸ªçŠ¶æ€æ‘˜è¦')
    
    args = parser.parse_args()
    
    if args.check:
        print("ğŸ” æ£€æŸ¥ç¯å¢ƒé…ç½®...")
        deps_ok = check_dependencies()
        if deps_ok:
            print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        else:
            print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return
    
    if args.demo:
        print("ğŸ¯ è¿è¡Œæ¼”ç¤ºæ¨¡å¼...")
        print("ğŸ“‹ æ”¯æŒçš„åŠŸèƒ½:")
        print("  - ACM CCS è®ºæ–‡ä¸‹è½½")
        print("  - IEEE S&P è®ºæ–‡ä¸‹è½½")
        print("  - NDSS è®ºæ–‡ä¸‹è½½")
        print("  - USENIX Security è®ºæ–‡ä¸‹è½½")
        print("  - è®ºæ–‡ä»£ç é“¾æ¥æå–")
        print("  - ä»£ç è´¨é‡åˆ†æ")
        print("  - æ–‡æ¡£ç”Ÿæˆ")
        print("ğŸ’¡ æ‰€æœ‰åŠŸèƒ½å®Œå…¨å¯ç”¨!")
        return
    
    if not check_dependencies():
        print("\nğŸ“¦ å®‰è£…ä¾èµ–:")
        print("pip install requests lxml urllib3 aiohttp beautifulsoup4 pdfplumber")
        sys.exit(1)
    
    # å¤„ç†å­¦è€…è¿½è¸ªå‘½ä»¤
    if args.command == 'track':
        run_scholar_tracking(args)
        return
    
    if args.conference and args.year:
        # æ‰€æœ‰ä¼šè®®ä½¿ç”¨ç›¸åŒçš„ä¸‹è½½é€»è¾‘
        if args.no_smart:
            smart_mode = False  # æ˜ç¡®ç¦ç”¨æ™ºèƒ½æ¨¡å¼
        elif args.smart:
            smart_mode = True   # æ˜ç¡®å¯ç”¨æ™ºèƒ½æ¨¡å¼
        else:
            smart_mode = True   # é»˜è®¤å¯ç”¨æ™ºèƒ½æ¨¡å¼
        
        mode_desc = "æ™ºèƒ½åŠ é€Ÿæ¨¡å¼" if smart_mode else "ä¼ ç»Ÿç¨³å®šæ¨¡å¼"
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {args.conference.upper()} {args.year} è®ºæ–‡ ({mode_desc})...")
        simple_paper_download(args.conference, args.year, args.url, smart_mode)
    else:
        print("ğŸ“ ä½¿ç”¨å¸®åŠ©:")
        print("  æ£€æŸ¥ç¯å¢ƒ: python main.py --check")
        print("  æŸ¥çœ‹æ¼”ç¤º: python main.py --demo")
        print("  ä¸‹è½½è®ºæ–‡ (é»˜è®¤æ™ºèƒ½æ¨¡å¼):")
        print("    CCS:    python main.py --conference ccs --year 23")
        print("    S&P:    python main.py --conference sp --year 23")
        print("    NDSS:   python main.py --conference ndss --year 23")
        print("    USENIX: python main.py --conference usenix --year 23")
        print("  å…³é—­æ™ºèƒ½æ¨¡å¼ (ä¼ ç»Ÿç¨³å®šæ¨¡å¼):")
        print("    python main.py --conference ndss --year 23 --no-smart")
        print("  å­¦è€…è¿½è¸ª:")
        print("    python main.py track --summary")
        print("    python main.py track")
        print("    python main.py track --scholar-id 1741101")
        print("    python main.py track --force")
        print("  æŸ¥çœ‹å¸®åŠ©: python main.py --help")
        print("ğŸ’¡ æ³¨æ„: æ‰€æœ‰ä¼šè®®éƒ½ä½¿ç”¨ç›¸åŒçš„ä¸‹è½½æ–¹å¼ï¼Œæ”¯æŒä¸åŒå¹´ä»½")
        print("ğŸ¤– æ™ºèƒ½æ¨¡å¼é»˜è®¤å¯ç”¨ï¼Œæä¾›æ›´å¿«çš„ä¸‹è½½é€Ÿåº¦å’Œè¿›åº¦æ˜¾ç¤º")


def run_scholar_tracking(args):
    """è¿è¡Œå­¦è€…è¿½è¸ªåŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ“š PaperBot å­¦è€…è¿½è¸ªç³»ç»Ÿ")
    print("=" * 60)

    config_path = Path(args.config).expanduser()
    if not config_path.is_absolute():
        config_path = current_dir / config_path
    config_path = config_path.resolve()
    if not config_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è®¢é˜…é…ç½®æ–‡ä»¶: {config_path}")
        return

    async def _run_tracking():
        from scholar_tracking import PaperTrackerAgent, ScholarProfileAgent
        from scholar_tracking.models import PaperMeta
        from core.workflow_coordinator import ScholarWorkflowCoordinator

        overrides = {"subscriptions_config_path": str(config_path)}
        profile_agent = ScholarProfileAgent(overrides)

        # æ˜¾ç¤ºæ‘˜è¦
        if args.summary:
            print("\nğŸ“Š è¿½è¸ªçŠ¶æ€æ‘˜è¦:")
            print(profile_agent.summary())
            return

        settings = profile_agent.get_settings()
        reporting_cfg = settings.get("reporting", {})
        min_score = settings.get("min_influence_score", 0)

        tracker_agent = PaperTrackerAgent({**overrides, "api": settings.get("api", {})})
        coordinator = ScholarWorkflowCoordinator(
            {
                "output_dir": str(profile_agent.get_output_dir()),
                "report_template": reporting_cfg.get("template", "paper_report.md.j2"),
                "use_documentation_agent": False, # ç¦ç”¨ DocumentationAgent ä»¥é¿å…æ¥å£ä¸åŒ¹é…
            }
        )

        # å¼ºåˆ¶æ¨¡å¼
        if args.force and args.scholar_id:
            print(f"\nğŸ”„ å¼ºåˆ¶é‡æ–°æ£€æµ‹å­¦è€…: {args.scholar_id}")
            profile_agent.clear_scholar_cache(args.scholar_id)
        elif args.force:
            print("\nğŸ”„ æ¸…é™¤æ‰€æœ‰ç¼“å­˜...")
            profile_agent.clear_all_cache()

        # è¿½è¸ªå­¦è€…
        if args.scholar_id:
            scholar = profile_agent.get_scholar_by_id(args.scholar_id)
            if not scholar:
                print(f"âŒ æœªæ‰¾åˆ°å­¦è€…: {args.scholar_id}")
                return
            result = await tracker_agent.track_scholar(scholar, dry_run=args.dry_run)
            results = [result]
            await tracker_agent.ss_agent.close()
        else:
            print("\nğŸ” å¼€å§‹è¿½è¸ªæ‰€æœ‰è®¢é˜…å­¦è€…...")
            results = await tracker_agent.track_all_scholars(dry_run=args.dry_run)

        # æ˜¾ç¤ºç»“æœ
        total_new = 0
        for result in results:
            scholar_name = result.get("scholar_name", "Unknown")
            new_count = result.get("new_papers_count", len(result.get("new_papers", [])))
            status = result.get("status", "unknown")

            if status == "success":
                print(f"  âœ… {scholar_name}: å‘ç° {new_count} ç¯‡æ–°è®ºæ–‡")
                total_new += new_count
            elif status == "error":
                print(f"  âŒ {scholar_name}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"  âš ï¸  {scholar_name}: {status}")

        print(f"\nğŸ“ˆ æ€»è®¡å‘ç° {total_new} ç¯‡æ–°è®ºæ–‡")

        if total_new == 0:
            print("\nâœ… å­¦è€…è¿½è¸ªå®Œæˆ!")
            return

        persist_reports = not args.dry_run
        if args.dry_run:
            print("\nğŸ§ª Dry-Run æ¨¡å¼ï¼šå°†è¿è¡Œåˆ†æä½†ä¸å†™å…¥ Markdown æ–‡ä»¶ã€‚")
        else:
            print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")

        for result in results:
            if result.get("status") != "success":
                continue

            scholar_name = result.get("scholar_name")
            new_papers = result.get("new_papers", [])

            if not new_papers:
                continue

            print(f"\n  å¤„ç† {scholar_name} çš„ {len(new_papers)} ç¯‡è®ºæ–‡...")
            papers = [PaperMeta.from_dict(p) for p in new_papers]
            processed_records = []

            for paper in papers:
                try:
                    report_path, influence, pipeline_data = await coordinator.run_paper_pipeline(
                        paper,
                        scholar_name,
                        persist_report=persist_reports,
                    )

                    pis = f"{influence.total_score:.1f}/100 ({influence.recommendation.value})"
                    if report_path:
                        print(f"    ğŸ“„ {paper.title[:40]}... -> {report_path.name} | PIS {pis}")
                    else:
                        print(f"    ğŸ“„ {paper.title[:40]}... -> (æœªæŒä¹…åŒ–) | PIS {pis}")

                    processed_records.append(
                        {
                            "paper_id": paper.paper_id,
                            "title": paper.title,
                            "report_path": str(report_path) if report_path else None,
                            "pis": round(influence.total_score, 2),
                            "recommendation": influence.recommendation.value,
                            "status": pipeline_data.get("status", "success"),
                        }
                    )
                except Exception as e:
                    print(f"    âŒ å¤„ç†å¤±è´¥: {paper.title[:40]}... - {e}")
                    processed_records.append(
                        {
                            "paper_id": paper.paper_id,
                            "title": paper.title,
                            "status": f"failed: {e}",
                        }
                    )

            scholar_id = result.get("scholar_id")
            if (
                processed_records
                and scholar_id
                and reporting_cfg.get("persist_history", True)
            ):
                profile_agent.record_processed_papers(
                    scholar_id,
                    processed_records,
                )

        print("\nâœ… å­¦è€…è¿½è¸ªå®Œæˆ!")

    try:
        asyncio.run(_run_tracking())
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è¿½è¸ªè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()