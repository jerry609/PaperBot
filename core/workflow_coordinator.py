# core/workflow_coordinator.py
"""
MVP ç‰ˆå·¥ä½œæµåè°ƒå™¨
ç”¨äºä¸²è”å¤š Agent å®Œæˆå­¦è€…è¿½è¸ªè®ºæ–‡åˆ†ææµæ°´çº¿
"""

import logging
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from pathlib import Path

from agents import (
    ResearchAgent,
    CodeAnalysisAgent,
    QualityAgent,
    DocumentationAgent,
)
from scholar_tracking.models import PaperMeta, CodeMeta
from scholar_tracking.models.influence import InfluenceResult
from influence import InfluenceCalculator
from reports.writer import ReportWriter
from core.collaboration import (
    CollaborationBus,
    HostOrchestrator,
    HostConfig,
    AgentMessage,
    MessageType,
)
from core.report_engine import ReportEngine, ReportEngineConfig

logger = logging.getLogger(__name__)


class ScholarWorkflowCoordinator:
    """
    å­¦è€…è¿½è¸ªå·¥ä½œæµåè°ƒå™¨ (MVP ç‰ˆ)
    
    é¡ºåºæ‰§è¡Œæµæ°´çº¿:
    1. ResearchAgent â†’ æ‰©å±•æ‘˜è¦ + ä»£ç ä»“åº“é“¾æ¥
    2. CodeAnalysisAgent â†’ ä»£ç è´¨é‡åˆ†æ
    3. QualityAgent â†’ ç»¼åˆè´¨é‡è¯„ä»·
    4. InfluenceCalculator â†’ PIS è¯„åˆ†
    5. DocumentationAgent â†’ ç”Ÿæˆ Markdown æŠ¥å‘Š
    """
    
    def __init__(
        self,
        config: Optional[Dict[str, Any]] = None,
        report_writer: Optional[ReportWriter] = None,
    ):
        """
        åˆå§‹åŒ–åè°ƒå™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config or {}
        self.logger = logging.getLogger(self.__class__.__name__)
        self.collab_settings = self.config.get("collab", {})
        
        # åˆå§‹åŒ– Agents
        self.research_agent = ResearchAgent(config)
        self.code_analysis_agent = CodeAnalysisAgent(config)
        self.quality_agent = QualityAgent(config)
        self.documentation_agent = DocumentationAgent(config)
        
        # åˆå§‹åŒ–å½±å“åŠ›è®¡ç®—å™¨
        self.influence_calculator = InfluenceCalculator(config)

        # æŠ¥å‘Šæ¸²æŸ“å™¨
        output_dir = None
        if self.config.get("output_dir"):
            output_dir = Path(self.config["output_dir"])
        template_name = self.config.get("report_template", "paper_report.md.j2")
        self.report_writer = report_writer or ReportWriter(
            output_dir=output_dir,
            template_name=template_name,
        )

        # åä½œæ€»çº¿ä¸ä¸»æŒäºº
        self.collab_bus = CollaborationBus()
        self.host = HostOrchestrator(self._build_host_config())
        self.collab_enabled = bool(self.collab_settings.get("enabled", True))

        # Report Engine
        self.report_engine_cfg = self._build_report_engine_config()
        self.report_engine = ReportEngine(self.report_engine_cfg)

        # å¤ç°ç»“æœå ä½
        self._latest_repro = None
        self._env_info = self._build_env_info()
    
    async def run_paper_pipeline(
        self,
        paper: PaperMeta,
        scholar_name: Optional[str] = None,
        persist_report: bool = True,
    ) -> Tuple[Optional[Path], InfluenceResult, Dict[str, Any]]:
        """
        è¿è¡Œè®ºæ–‡åˆ†ææµæ°´çº¿
        
        Args:
            paper: è®ºæ–‡å…ƒæ•°æ®
            scholar_name: å­¦è€…åç§°ï¼ˆç”¨äºæŠ¥å‘Šç”Ÿæˆï¼‰
            persist_report: æ˜¯å¦å†™å…¥ Markdown æ–‡ä»¶
            
        Returns:
            (report_path, influence_result, pipeline_data)
        """
        self._validate_paper_meta(paper)
        self._current_paper_ctx = {
            "paper_id": paper.paper_id,
            "paper_title": paper.title,
        }
        pipeline_data = {
            "paper_id": paper.paper_id,
            "paper_title": paper.title,
            "scholar_name": scholar_name,
            "started_at": datetime.now().isoformat(),
            "stages": {},
            "errors": [],
            "collab_log_path": None,
        }
        
        code_meta = None
        research_result = {}
        code_analysis_result = {}
        quality_result = {}
        report_path: Optional[Path] = None
        report_markdown: Optional[str] = None
        
        try:
            # Stage 1: Research Agent - æ‰©å±•æ‘˜è¦å’Œä»£ç ä»“åº“å‘ç°
            self.logger.info(f"[1/5] Running ResearchAgent for: {paper.title[:50]}...")
            try:
                research_result = await self._run_research_stage(paper)
                pipeline_data["stages"]["research"] = {
                    "status": "success",
                    "result": research_result,
                }
                self._emit_stage_message(
                    stage="research",
                    content=f"ResearchAgent å®Œæˆ: {paper.title}",
                    payload=research_result,
                )
                
                # ä»ç ”ç©¶ç»“æœä¸­æå–ä»£ç ä»“åº“ä¿¡æ¯
                if research_result.get("github_url"):
                    paper.github_url = research_result["github_url"]
                    paper.has_code = True
            except Exception as e:
                self.logger.warning(f"ResearchAgent failed: {e}")
                pipeline_data["stages"]["research"] = {"status": "failed", "error": str(e)}
                pipeline_data["errors"].append(f"Research: {e}")
            
            # Stage 2: Code Analysis Agent - ä»£ç åˆ†æ
            self.logger.info(f"[2/5] Running CodeAnalysisAgent...")
            if paper.github_url or paper.has_code:
                try:
                    code_analysis_result = await self._run_code_analysis_stage(paper)
                    pipeline_data["stages"]["code_analysis"] = {
                        "status": "success",
                        "result": code_analysis_result,
                    }
                    self._emit_stage_message(
                        stage="code_analysis",
                        content="CodeAnalysisAgent å®Œæˆ",
                        payload=code_analysis_result,
                    )
                    
                    # æ„å»º CodeMeta
                    code_meta = self._build_code_meta(paper, code_analysis_result)
                except Exception as e:
                    self.logger.warning(f"CodeAnalysisAgent failed: {e}")
                    pipeline_data["stages"]["code_analysis"] = {"status": "failed", "error": str(e)}
                    pipeline_data["errors"].append(f"CodeAnalysis: {e}")
                    self._emit_stage_message(
                        stage="code_analysis",
                        content=f"CodeAnalysisAgent å¤±è´¥: {e}",
                        payload={"error": str(e)},
                        message_type=MessageType.ERROR,
                    )
            else:
                pipeline_data["stages"]["code_analysis"] = {"status": "skipped", "reason": "no code"}
                self._emit_stage_message(
                    stage="code_analysis",
                    content="CodeAnalysisAgent è·³è¿‡ï¼ˆæ— ä»£ç ä»“åº“ï¼‰",
                    payload={"reason": "no code"},
                    message_type=MessageType.RESULT,
                )
            
            # Stage 3: Quality Agent - è´¨é‡è¯„ä¼°
            self.logger.info(f"[3/5] Running QualityAgent...")
            try:
                quality_result = await self._run_quality_stage(
                    paper, research_result, code_analysis_result
                )
                pipeline_data["stages"]["quality"] = {
                    "status": "success",
                    "result": quality_result,
                }
                # æ•è·å¤ç°/å¯è¿è¡Œæ€§ç»“æœï¼ˆå¦‚æœä¸‹æ¸¸è´¨é‡é˜¶æ®µå·²æœ‰ï¼‰
                if quality_result.get("repro"):
                    self._latest_repro = quality_result.get("repro")
                self._emit_stage_message(
                    stage="quality",
                    content="QualityAgent å®Œæˆ",
                    payload=quality_result,
                )
            except Exception as e:
                self.logger.warning(f"QualityAgent failed: {e}")
                pipeline_data["stages"]["quality"] = {"status": "failed", "error": str(e)}
                pipeline_data["errors"].append(f"Quality: {e}")
                self._emit_stage_message(
                    stage="quality",
                    content=f"QualityAgent å¤±è´¥: {e}",
                    payload={"error": str(e)},
                    message_type=MessageType.ERROR,
                )
            
            # Stage 4: Influence Calculator - å½±å“åŠ›è¯„åˆ†
            self.logger.info(f"[4/5] Calculating influence score...")
            influence_result = self.influence_calculator.calculate(paper, code_meta)
            pipeline_data["stages"]["influence"] = {
                "status": "success",
                "result": influence_result.to_dict(),
            }
            self._emit_stage_message(
                stage="influence",
                content="InfluenceCalculator å®Œæˆ",
                payload=influence_result.to_dict(),
            )
            
            # Stage 5: Report Rendering
            self.logger.info(f"[5/5] Generating report...")
            try:
                report_markdown = await self._generate_report(
                    paper=paper,
                    scholar_name=scholar_name,
                    research_result=self._ensure_defaults(research_result, default={}),
                    code_analysis_result=self._ensure_defaults(
                        code_analysis_result,
                        default={"repo_url": paper.github_url, "repo_name": None},
                    ),
                    quality_result=self._ensure_defaults(quality_result, default={}),
                    influence_result=influence_result,
                    env_info=self._env_info,
                )
                pipeline_data["stages"]["documentation"] = {"status": "success"}
            except Exception as e:
                self.logger.warning(f"Documentation stage failed: {e}")
                pipeline_data["stages"]["documentation"] = {
                    "status": "failed",
                    "error": str(e),
                }
                pipeline_data["errors"].append(f"Documentation: {e}")
                report_markdown = self._generate_fallback_report(
                    paper, influence_result, pipeline_data
                )
                self._emit_stage_message(
                    stage="documentation",
                    content="DocumentationAgent å®Œæˆ",
                    payload={"has_report": bool(report_markdown)},
                )

            # æ–°ç‰ˆ Report Engine è¾“å‡º
            if self.report_engine_cfg.enabled:
                try:
                    re_result = self._run_report_engine(
                        topic=paper.title,
                        summary=research_result.get("summary", ""),
                        sections_context={
                            "paper": paper.to_dict(),
                            "research": research_result,
                            "code_analysis": code_analysis_result,
                            "quality": quality_result,
                            "influence": influence_result.to_dict(),
                            "repro": self._latest_repro,
                            "env_info": self._env_info,
                            "data_time": pipeline_data.get("started_at"),
                        },
                        task_id=paper.paper_id or paper.title,
                    )
                    pipeline_data["stages"]["report_engine"] = {
                        "status": "success",
                        "html": str(re_result.html_path) if re_result.html_path else None,
                        "pdf": str(re_result.pdf_path) if re_result.pdf_path else None,
                        "ir": str(re_result.ir_path) if re_result.ir_path else None,
                    }
                except Exception as exc:
                    self.logger.warning(f"ReportEngine ç”Ÿæˆå¤±è´¥: {exc}")
                    pipeline_data["stages"]["report_engine"] = {"status": "failed", "error": str(exc)}
                    pipeline_data["errors"].append(f"ReportEngine: {exc}")
            
            # æŒä¹…åŒ–æŠ¥å‘Š
            if report_markdown:
                if persist_report:
                    try:
                        report_path = self.report_writer.write_report(
                            report_markdown,
                            paper,
                            scholar_name,
                        )
                        pipeline_data["report_path"] = str(report_path)
                    except Exception as e:
                        self.logger.error(f"Failed to write report: {e}")
                        pipeline_data["errors"].append(f"ReportWrite: {e}")
                        pipeline_data["report_content"] = report_markdown
                else:
                    pipeline_data["report_content"] = report_markdown
            
            pipeline_data["completed_at"] = datetime.now().isoformat()
            pipeline_data["status"] = "success" if not pipeline_data["errors"] else "partial"

            # æŒä¹…åŒ–åä½œæ—¥å¿—
            pipeline_data["collab_log_path"] = str(self._persist_collab_log(paper))
            
            return report_path, influence_result, pipeline_data
            
        except Exception as e:
            self.logger.error(f"Pipeline failed for {paper.title}: {e}")
            pipeline_data["status"] = "failed"
            pipeline_data["errors"].append(str(e))
            
            # å³ä½¿å¤±è´¥ä¹Ÿè®¡ç®—å½±å“åŠ›åˆ†æ•°
            influence_result = self.influence_calculator.calculate(paper, None)
            report_markdown = self._generate_fallback_report(paper, influence_result, pipeline_data)
            
            if report_markdown and persist_report:
                try:
                    report_path = self.report_writer.write_report(
                        report_markdown,
                        paper,
                        scholar_name,
                    )
                    pipeline_data["report_path"] = str(report_path)
                except Exception as write_error:
                    self.logger.error(f"Failed to write fallback report: {write_error}")
                    pipeline_data["errors"].append(f"ReportWrite: {write_error}")
                    pipeline_data["report_content"] = report_markdown
            else:
                pipeline_data["report_content"] = report_markdown
            pipeline_data["collab_log_path"] = str(self._persist_collab_log(paper))
            return report_path, influence_result, pipeline_data

    # =========================================================
    # åä½œä¸ä¸»æŒäººè¾…åŠ©å‡½æ•°
    # =========================================================

    def _emit_stage_message(
        self,
        stage: str,
        content: str,
        payload: Optional[dict] = None,
        message_type: MessageType = MessageType.RESULT,
    ):
        """å†™å…¥åä½œæ€»çº¿å¹¶å°è¯•è§¦å‘ä¸»æŒäººå¼•å¯¼ã€‚"""
        if not self.collab_enabled:
            return
        msg = AgentMessage(
            sender=stage,
            message_type=message_type,
            content=content,
            metadata=payload or {},
            stage=stage,
        )
        self.collab_bus.add_message(msg)
        self._maybe_host_guidance(stage)

    def _maybe_host_guidance(self, stage: str):
        """ä¸»æŒäººæ ¹æ®æœ€è¿‘æ¶ˆæ¯ç”Ÿæˆå¼•å¯¼ï¼Œå¤±è´¥è‡ªåŠ¨é™çº§ã€‚"""
        if not self.collab_enabled or not self.host.is_available():
            return
        recent = self.collab_bus.latest_messages(limit=20)
        guidance = self.host.generate_guidance(
            messages=recent,
            context={**(self._current_paper_ctx or {}), "stage": stage},
        )
        if guidance:
            self.collab_bus.add_host_message(guidance, stage=stage)
            self.collab_bus.next_round()

    def _persist_collab_log(self, paper: PaperMeta) -> Path:
        """æŒä¹…åŒ–åä½œæ—¥å¿—åˆ° output/collab_logs ä¸‹ã€‚"""
        base_dir = self.config.get("output_dir") or "./output"
        log_dir = Path(base_dir) / "collab_logs"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{paper.paper_id or 'paper'}_{timestamp}.jsonl"
        return self.collab_bus.persist(log_dir / filename)

    def _build_host_config(self) -> HostConfig:
        """ä»é…ç½®æ„é€ ä¸»æŒäººé…ç½®ï¼Œç¼ºçœä½¿ç”¨é€šç”¨ OpenAI Keyã€‚"""
        host_cfg = self.collab_settings.get("host", {})
        api_key = host_cfg.get("api_key") or self.config.get("openai_api_key") or self.config.get("api_key")
        model = host_cfg.get("model") or self.config.get("host_model") or "gpt-4o-mini"
        base_url = host_cfg.get("base_url") or self.config.get("host_base_url")
        enabled = bool(host_cfg.get("enabled", False))
        return HostConfig(
            enabled=enabled,
            api_key=api_key,
            model=model,
            base_url=base_url,
            temperature=host_cfg.get("temperature", 0.3),
            top_p=host_cfg.get("top_p", 0.9),
        )

    def _build_report_engine_config(self) -> ReportEngineConfig:
        cfg = self.config.get("report_engine", {})
        return ReportEngineConfig(
            enabled=cfg.get("enabled", False),
            api_key=cfg.get("api_key") or self.config.get("openai_api_key"),
            model=cfg.get("model", "gpt-4o-mini"),
            base_url=cfg.get("base_url"),
            output_dir=Path(cfg.get("output_dir", "output/reports")),
            template_dir=Path(cfg.get("template_dir", "core/report_engine/templates")),
            pdf_enabled=cfg.get("pdf_enabled", True),
            max_words=cfg.get("max_words", 6000),
        )

    def _run_report_engine(
        self,
        topic: str,
        summary: str,
        sections_context: Dict[str, Any],
        task_id: str,
    ):
        return self.report_engine.generate(
            topic=topic,
            summary=summary,
            sections_context=sections_context,
            task_id=task_id,
            enable_pdf=self.report_engine_cfg.pdf_enabled,
        )

    def _build_env_info(self) -> str:
        """æ„é€ ç¯å¢ƒä¿¡æ¯æ‘˜è¦ï¼ˆæ¨¡å‹/é•œåƒ/èµ„æºé™åˆ¶ï¼‰ã€‚"""
        parts = []
        if self.report_engine_cfg.enabled:
            parts.append(f"ReportEngineModel={self.report_engine_cfg.model}")
        repro_cfg = self.config.get("repro", {})
        if repro_cfg:
            parts.append(f"DockerImage={repro_cfg.get('docker_image','')}")
            parts.append(f"CPU={repro_cfg.get('cpu_shares','')}")
            parts.append(f"Mem={repro_cfg.get('mem_limit','')}")
            parts.append(f"Network={repro_cfg.get('network')}")
        return "; ".join([p for p in parts if p])
    
    async def _run_research_stage(self, paper: PaperMeta) -> Dict[str, Any]:
        """è¿è¡Œç ”ç©¶é˜¶æ®µ"""
        # è°ƒç”¨ ResearchAgent è·å–æ›´å¤šè®ºæ–‡ä¿¡æ¯
        result = await self.research_agent.process(
            paper_title=paper.title,
            paper_id=paper.paper_id,
            abstract=paper.abstract,
        )
        return result if isinstance(result, dict) else {"raw": str(result)}
    
    async def _run_code_analysis_stage(self, paper: PaperMeta) -> Dict[str, Any]:
        """è¿è¡Œä»£ç åˆ†æé˜¶æ®µ"""
        if not paper.github_url:
            return {"status": "no_code_url"}
        
        result = await self.code_analysis_agent.process(
            repo_url=paper.github_url,
        )
        return result if isinstance(result, dict) else {"raw": str(result)}
    
    async def _run_quality_stage(
        self,
        paper: PaperMeta,
        research_result: Dict[str, Any],
        code_analysis_result: Dict[str, Any],
    ) -> Dict[str, Any]:
        """è¿è¡Œè´¨é‡è¯„ä¼°é˜¶æ®µ"""
        # åˆå¹¶ä¸Šä¸‹æ–‡ä¿¡æ¯
        context = {
            "paper": paper.to_dict(),
            "research": research_result,
            "code_analysis": code_analysis_result,
        }
        
        result = await self.quality_agent.process(context)
        return result if isinstance(result, dict) else {"raw": str(result)}
    
    def _build_code_meta(
        self,
        paper: PaperMeta,
        code_analysis_result: Dict[str, Any],
    ) -> Optional[CodeMeta]:
        """ä»ä»£ç åˆ†æç»“æœæ„å»º CodeMeta"""
        if not paper.github_url:
            return None
        
        try:
            return CodeMeta(
                repo_url=paper.github_url,
                repo_name=code_analysis_result.get("repo_name"),
                stars=code_analysis_result.get("stars", 0),
                forks=code_analysis_result.get("forks", 0),
                language=code_analysis_result.get("language"),
                updated_at=code_analysis_result.get("updated_at"),
                has_readme=code_analysis_result.get("has_readme", False),
                reproducibility_score=code_analysis_result.get("reproducibility_score"),
            )
        except Exception as e:
            self.logger.warning(f"Failed to build CodeMeta: {e}")
            return CodeMeta(repo_url=paper.github_url)
    
    async def _generate_report(
        self,
        paper: PaperMeta,
        scholar_name: Optional[str],
        research_result: Dict[str, Any],
        code_analysis_result: Dict[str, Any],
        quality_result: Dict[str, Any],
        influence_result: InfluenceResult,
    ) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ Markdown æŠ¥å‘Š"""
        # è°ƒç”¨ Jinja æ¨¡æ¿ç”ŸæˆæŠ¥å‘Šï¼Œå¯é€‰åœ°ä½¿ç”¨ DocumentationAgent ä¸°å¯Œå†…å®¹
        report_data = {
            "paper": paper.to_dict(),
            "scholar_name": scholar_name,
            "research": research_result,
            "code_analysis": code_analysis_result,
            "quality": quality_result,
            "influence": influence_result.to_dict(),
        }

        if self.config.get("use_documentation_agent"):
            try:
                doc_result = await self.documentation_agent.process(report_data)
                report_data["documentation_agent"] = doc_result
            except Exception as e:
                self.logger.warning(f"DocumentationAgent enrichment failed: {e}")
        
        return self.report_writer.render_template(
            paper=paper,
            influence=influence_result,
            research_result=research_result,
            code_analysis_result=code_analysis_result,
            quality_result=quality_result,
            scholar_name=scholar_name,
        )
    
    def _generate_fallback_report(
        self,
        paper: PaperMeta,
        influence_result: InfluenceResult,
        pipeline_data: Dict[str, Any],
    ) -> str:
        """ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Šï¼ˆå½“ DocumentationAgent å¤±è´¥æ—¶ï¼‰"""
        authors = ", ".join(paper.authors) if paper.authors else "æœªçŸ¥"
        
        report = f"""# {paper.title}

## ğŸ“‹ å…ƒä¿¡æ¯

| å±æ€§ | å€¼ |
|------|-----|
| ä½œè€… | {authors} |
| å¹´ä»½ | {paper.year or 'æœªçŸ¥'} |
| å‘è¡¨äº | {paper.venue or 'æœªçŸ¥'} |
| å¼•ç”¨æ•° | {paper.citation_count} |
| Semantic Scholar ID | {paper.paper_id} |

## ğŸ“ æ‘˜è¦

{paper.abstract or paper.tldr or 'æš‚æ— æ‘˜è¦'}

## ğŸ’» ä»£ç ä¿¡æ¯

"""
        if paper.github_url:
            report += f"- **ä»“åº“åœ°å€**: [{paper.github_url}]({paper.github_url})\n"
        else:
            report += "æœªå‘ç°å…¬å¼€ä»£ç ä»“åº“\n"
        
        report += f"""
## ğŸ“Š å½±å“åŠ›è¯„åˆ† (PIS)

| æŒ‡æ ‡ | åˆ†æ•° |
|------|------|
| **æ€»åˆ†** | {influence_result.total_score:.1f}/100 |
| å­¦æœ¯å½±å“åŠ› | {influence_result.academic_score:.1f}/100 |
| å·¥ç¨‹å½±å“åŠ› | {influence_result.engineering_score:.1f}/100 |

{influence_result.explanation}

## ğŸ¯ æ¨èçº§åˆ«

**{influence_result.recommendation.value}**

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*ç”± PaperBot è‡ªåŠ¨ç”Ÿæˆ*
"""
        return report

    def _validate_paper_meta(self, paper: PaperMeta) -> None:
        """æœ€å°æ ¡éªŒï¼Œæå‰å‘ç°å¿…å¡«å­—æ®µç¼ºå¤±"""
        missing = []
        if not paper.paper_id:
            missing.append("paper_id")
        if not paper.title:
            missing.append("title")
        if missing:
            raise ValueError(f"PaperMeta missing required fields: {', '.join(missing)}")

    def _ensure_defaults(self, value: Any, default: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ç¡®ä¿ä¼ é€’ç»™æ¨¡æ¿çš„æ•°æ®åŒ…å«é»˜è®¤å­—æ®µï¼Œé¿å… KeyError"""
        if not isinstance(value, dict):
            return default or {}
        merged = dict(default or {})
        merged.update({k: v for k, v in value.items() if v is not None})
        return merged
    
    async def run_batch_pipeline(
        self,
        papers: List[PaperMeta],
        scholar_name: Optional[str] = None,
    ) -> List[Tuple[str, InfluenceResult, Dict[str, Any]]]:
        """
        æ‰¹é‡è¿è¡Œè®ºæ–‡åˆ†ææµæ°´çº¿
        
        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            scholar_name: å­¦è€…åç§°
            
        Returns:
            ç»“æœåˆ—è¡¨
        """
        results = []
        total = len(papers)
        
        for i, paper in enumerate(papers, 1):
            self.logger.info(f"Processing paper {i}/{total}: {paper.title[:50]}...")
            
            try:
                result = await self.run_paper_pipeline(paper, scholar_name)
                results.append(result)
            except Exception as e:
                self.logger.error(f"Failed to process paper: {e}")
                # åˆ›å»ºå¤±è´¥ç»“æœ
                influence = self.influence_calculator.calculate(paper, None)
                fallback_report = self._generate_fallback_report(
                    paper, influence, {"error": str(e)}
                )
                results.append(
                    (
                        None,
                        influence,
                        {
                            "status": "failed",
                            "error": str(e),
                            "report_content": fallback_report,
                        },
                    )
                )
        
        return results
