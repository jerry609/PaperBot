# utils/smart_downloader.py

import asyncio
import time
from typing import Dict, List, Any, Optional
from collections import deque
from dataclasses import dataclass
import logging
from .downloader import PaperDownloader

@dataclass
class DownloadStats:
    """ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯"""
    total_attempts: int = 0
    successful_downloads: int = 0
    failed_downloads: int = 0
    cached_hits: int = 0
    avg_download_time: float = 0.0
    current_success_rate: float = 1.0
    consecutive_failures: int = 0

class SmartDownloadManager:
    """æ™ºèƒ½ä¸‹è½½ç®¡ç†å™¨ - åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # åˆ›å»ºåŸºç¡€ä¸‹è½½å™¨
        self.downloader = PaperDownloader(config)
        
        # å¹¶å‘æ§åˆ¶å‚æ•°
        self.min_concurrent = 1      # æœ€å°å¹¶å‘æ•°
        self.max_concurrent = 4      # æœ€å¤§å¹¶å‘æ•°  
        self.current_concurrent = 2  # å½“å‰å¹¶å‘æ•°
        
        # æ€§èƒ½ç›‘æ§å‚æ•°
        self.stats = DownloadStats()
        self.recent_times = deque(maxlen=10)  # æœ€è¿‘10æ¬¡ä¸‹è½½æ—¶é—´
        self.adjustment_threshold = 5         # è°ƒæ•´å¹¶å‘æ•°çš„è¯„ä¼°å‘¨æœŸ
        
        # å®‰å…¨å‚æ•°
        self.failure_threshold = 0.3  # å¤±è´¥ç‡é˜ˆå€¼ (30%)
        self.slow_threshold = 10.0    # æ…¢ä¸‹è½½é˜ˆå€¼ (10ç§’)
        self.rest_interval = 1.0      # è¯·æ±‚é—´éš”
        
        # åˆ›å»ºä¿¡å·é‡
        self.semaphore = asyncio.Semaphore(self.current_concurrent)
        
        self.logger.info(f"æ™ºèƒ½ä¸‹è½½ç®¡ç†å™¨åˆå§‹åŒ– - å¹¶å‘èŒƒå›´: {self.min_concurrent}-{self.max_concurrent}")

    async def download_papers_smart(self, papers: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ™ºèƒ½æ‰¹é‡ä¸‹è½½è®ºæ–‡"""
        if not papers:
            return []
        
        valid_papers = [p for p in papers if p.get('url') and p.get('url').strip()]
        if not valid_papers:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„PDFä¸‹è½½é“¾æ¥")
            return []
        
        self.logger.info(f"ğŸš€ å¼€å§‹æ™ºèƒ½ä¸‹è½½ {len(valid_papers)} ç¯‡è®ºæ–‡")
        self.logger.info(f"ğŸ“Š åˆå§‹å¹¶å‘æ•°: {self.current_concurrent}")
        
        start_time = time.time()
        results = []
        
        # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
        batch_size = max(8, self.current_concurrent * 2)  # æ‰¹æ¬¡å¤§å°
        
        for i in range(0, len(valid_papers), batch_size):
            batch = valid_papers[i:i + batch_size]
            batch_results = await self._process_batch(batch, i, len(valid_papers))
            results.extend(batch_results)
            
            # åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
            await self._adjust_concurrency()
            
            # æ‰¹æ¬¡é—´ä¼‘æ¯
            if i + batch_size < len(valid_papers):
                await asyncio.sleep(self.rest_interval)
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        self._print_final_stats(results, total_time)
        
        return results

    async def _process_batch(self, batch: List[Dict[str, Any]], start_idx: int, total: int) -> List[Dict[str, Any]]:
        """å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„ä¸‹è½½"""
        self.logger.info(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ [{start_idx+1}-{min(start_idx+len(batch), total)}/{total}] - å¹¶å‘æ•°: {self.current_concurrent}")
        
        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
        tasks = []
        for i, paper in enumerate(batch):
            task = self._download_with_monitoring(paper, start_idx + i + 1, total)
            tasks.append(task)
        
        # æ‰§è¡Œæ‰¹æ¬¡ä¸‹è½½
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                self.logger.error(f"æ‰¹æ¬¡ä¸‹è½½å¼‚å¸¸: {str(result)}")
                processed_results.append({'success': False, 'error': str(result)})
            else:
                processed_results.append(result)
        
        return processed_results

    async def _download_with_monitoring(self, paper: Dict[str, Any], index: int, total: int) -> Dict[str, Any]:
        """å¸¦ç›‘æ§çš„å•ç¯‡è®ºæ–‡ä¸‹è½½"""
        async with self.semaphore:
            start_time = time.time()
            
            try:
                print(f"ğŸ”„ [{index}/{total}] ä¸‹è½½: {paper['title'][:50]}...")
                
                # æ‰§è¡Œä¸‹è½½
                result = await self.downloader.download_paper(paper['url'], paper['title'])
                download_time = time.time() - start_time
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self._update_stats(result, download_time)
                
                # æ˜¾ç¤ºç»“æœ
                if result and result.get('success'):
                    if result.get('cached'):
                        print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­ (è€—æ—¶: {download_time:.1f}s)")
                    else:
                        size_kb = result.get('size', 0) / 1024
                        print(f"âœ… ä¸‹è½½æˆåŠŸ (è€—æ—¶: {download_time:.1f}s, å¤§å°: {size_kb:.1f}KB)")
                else:
                    error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯') if result else 'ä¸‹è½½å¤±è´¥'
                    print(f"âŒ ä¸‹è½½å¤±è´¥: {error_msg}")
                
                return result or {'success': False, 'error': 'ä¸‹è½½å¤±è´¥'}
                
            except Exception as e:
                download_time = time.time() - start_time
                self._update_stats({'success': False}, download_time)
                self.logger.error(f"ä¸‹è½½å¼‚å¸¸ [{index}/{total}]: {str(e)}")
                print(f"âŒ ä¸‹è½½å¼‚å¸¸: {str(e)}")
                return {'success': False, 'error': str(e)}

    def _update_stats(self, result: Dict[str, Any], download_time: float):
        """æ›´æ–°ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯"""
        self.stats.total_attempts += 1
        
        if result and result.get('success'):
            if result.get('cached'):
                self.stats.cached_hits += 1
            else:
                self.stats.successful_downloads += 1
                self.recent_times.append(download_time)
            self.stats.consecutive_failures = 0
        else:
            self.stats.failed_downloads += 1
            self.stats.consecutive_failures += 1
        
        # è®¡ç®—æˆåŠŸç‡
        if self.stats.total_attempts > 0:
            self.stats.current_success_rate = (
                self.stats.successful_downloads + self.stats.cached_hits
            ) / self.stats.total_attempts
        
        # è®¡ç®—å¹³å‡ä¸‹è½½æ—¶é—´
        if self.recent_times:
            self.stats.avg_download_time = sum(self.recent_times) / len(self.recent_times)

    async def _adjust_concurrency(self):
        """åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°"""
        if self.stats.total_attempts < self.adjustment_threshold:
            return  # æ ·æœ¬å¤ªå°‘ï¼Œä¸è°ƒæ•´
        
        old_concurrent = self.current_concurrent
        
        # å†³ç­–é€»è¾‘
        if self.stats.consecutive_failures >= 3:
            # è¿ç»­å¤±è´¥ï¼Œé™ä½å¹¶å‘
            self.current_concurrent = max(self.min_concurrent, self.current_concurrent - 1)
            reason = f"è¿ç»­å¤±è´¥{self.stats.consecutive_failures}æ¬¡"
            
        elif self.stats.current_success_rate < self.failure_threshold:
            # æˆåŠŸç‡å¤ªä½ï¼Œé™ä½å¹¶å‘
            self.current_concurrent = max(self.min_concurrent, self.current_concurrent - 1)
            reason = f"æˆåŠŸç‡è¿‡ä½({self.stats.current_success_rate:.1%})"
            
        elif self.stats.avg_download_time > self.slow_threshold:
            # å¹³å‡é€Ÿåº¦å¤ªæ…¢ï¼Œé™ä½å¹¶å‘
            self.current_concurrent = max(self.min_concurrent, self.current_concurrent - 1)
            reason = f"å¹³å‡é€Ÿåº¦è¿‡æ…¢({self.stats.avg_download_time:.1f}s)"
            
        elif (self.stats.current_success_rate > 0.8 and 
              self.stats.avg_download_time < 5.0 and 
              self.stats.consecutive_failures == 0):
            # è¡¨ç°è‰¯å¥½ï¼Œå¢åŠ å¹¶å‘
            self.current_concurrent = min(self.max_concurrent, self.current_concurrent + 1)
            reason = f"æ€§èƒ½è‰¯å¥½(æˆåŠŸç‡{self.stats.current_success_rate:.1%})"
        else:
            return  # ä¿æŒå½“å‰å¹¶å‘æ•°
        
        # å¦‚æœå¹¶å‘æ•°å‘ç”Ÿå˜åŒ–ï¼Œæ›´æ–°ä¿¡å·é‡
        if old_concurrent != self.current_concurrent:
            self.logger.info(f"ğŸ”§ è°ƒæ•´å¹¶å‘æ•°: {old_concurrent} â†’ {self.current_concurrent} ({reason})")
            
            # åˆ›å»ºæ–°çš„ä¿¡å·é‡
            self.semaphore = asyncio.Semaphore(self.current_concurrent)
            
            # è°ƒæ•´åç¨ä½œä¼‘æ¯
            await asyncio.sleep(2.0)

    def _print_final_stats(self, results: List[Dict[str, Any]], total_time: float):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        success_count = sum(1 for r in results if r.get('success'))
        cached_count = sum(1 for r in results if r.get('success') and r.get('cached'))
        download_count = success_count - cached_count
        
        print(f"\nğŸ‰ æ™ºèƒ½ä¸‹è½½å®Œæˆç»Ÿè®¡:")
        print(f"âœ… æˆåŠŸä¸‹è½½: {success_count}/{len(results)} ç¯‡è®ºæ–‡")
        print(f"ğŸ“‹ ç¼“å­˜å‘½ä¸­: {cached_count} ç¯‡")
        print(f"â¬‡ï¸  å®é™…ä¸‹è½½: {download_count} ç¯‡")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
        print(f"ğŸ”§ æœ€ç»ˆå¹¶å‘æ•°: {self.current_concurrent}")
        
        if download_count > 0:
            avg_time = total_time / download_count
            print(f"ğŸ“Š å¹³å‡é€Ÿåº¦: {avg_time:.2f} ç§’/ç¯‡")
        
        success_rate = success_count / len(results) if results else 0
        print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1%}")
        
        # æ€§èƒ½æ€»ç»“
        if success_rate >= 0.9:
            print(f"ğŸ† ä¸‹è½½æ€§èƒ½: ä¼˜ç§€")
        elif success_rate >= 0.8:
            print(f"ğŸ‘ ä¸‹è½½æ€§èƒ½: è‰¯å¥½")
        elif success_rate >= 0.6:
            print(f"âš ï¸  ä¸‹è½½æ€§èƒ½: ä¸€èˆ¬")
        else:
            print(f"âŒ ä¸‹è½½æ€§èƒ½: éœ€è¦ä¼˜åŒ–")